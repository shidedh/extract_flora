{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import fitz\n",
    "import re\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "import operator\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import string \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genus_blocks(page_df, draw, color = '#6c899e', w = 3):\n",
    "    genus_list = page_df['genus'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for g in genus_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['genus'] == g)]\n",
    "            g_x0 = temp_df['x0'].min()\n",
    "            g_y0 = temp_df['y0'].min()\n",
    "            g_x1 = temp_df['x1'].max()\n",
    "            g_y1 = temp_df['y1'].max()\n",
    "\n",
    "            draw.rectangle((g_x0, g_y0, g_x1, g_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "        \n",
    "def plot_epitet_blocks(page_df, draw, color = '#54081f', w = 2):\n",
    "    epitet_list = page_df['epitet'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for s in epitet_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['epitet'] == s)]\n",
    "            for g in temp_df['genus'].unique():\n",
    "                    \n",
    "                temp_g_df = temp_df[(temp_df['genus']) == g]\n",
    "                s_x0 = temp_g_df['x0'].min()\n",
    "                s_y0 = temp_g_df['y0'].min()\n",
    "                s_x1 = temp_g_df['x1'].max()\n",
    "                s_y1 = temp_g_df['y1'].max()\n",
    "\n",
    "                draw.rectangle((s_x0, s_y0, s_x1, s_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_blocks(page_df, draw, color = '#4a3757', w = 2):\n",
    "    block_list = page_df['block_no'].unique()\n",
    "    for i in block_list:\n",
    "        df_groupped = page_df[page_df['block_no'] == i]\n",
    "        x0_arr = df_groupped['x0'].min()\n",
    "        y0_arr = df_groupped['y0'].min()\n",
    "        x1_arr = df_groupped['x1'].max()\n",
    "        y1_arr = df_groupped['y1'].max()\n",
    "\n",
    "        draw.rectangle((x0_arr, y0_arr, x1_arr, y1_arr), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_author_blocks(page_df, draw, color = '#a3a3a3', w = 1):\n",
    "    epitet_list = page_df['epitet'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for s in epitet_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['epitet'] == s)]\n",
    "            for g in temp_df['genus'].unique():\n",
    "                temp_g_df = temp_df[(temp_df['genus'] == g) & (temp_df['word'] != s)]\n",
    "                a_x0 = temp_g_df['x0'].min()\n",
    "                a_y0 = temp_g_df['y0'].min()\n",
    "                a_x1 = temp_g_df['x1'].max()\n",
    "                a_y1 = temp_g_df['y1'].max()\n",
    "                \n",
    "                draw.rectangle((a_x0, a_y0, a_x1, a_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_sub_blocks(page_df, draw, color = '#ff6289', w = 1):\n",
    "    sub_list = page_df[(~page_df['sub'].isnull())]['sub'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for s in sub_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['sub'] == s)]\n",
    "            for b in temp_df['block_no'].unique():\n",
    "                temp_b_df = temp_df[(temp_df['block_no'] == b)]\n",
    "                for l in temp_b_df['line_no'].unique():\n",
    "                    temp_l_df = temp_b_df[temp_b_df['line_no'] == l]\n",
    "                    a_x0 = temp_l_df['x0'].min()\n",
    "                    a_y0 = temp_l_df['y0'].min()\n",
    "                    a_x1 = temp_l_df['x1'].max()\n",
    "                    a_y1 = temp_l_df['y1'].max()\n",
    "                \n",
    "                    draw.rectangle((a_x0, a_y0, a_x1, a_y1), fill=None, outline=ImageColor.getrgb(color), width = w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vol3 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = \"../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 3.pdf\"\n",
    "doc = fitz.open(pdf_dir)\n",
    "pages = [doc[i] for i in range(doc.pageCount)]\n",
    "index = list(range(555, 583))\n",
    "\n",
    "TARGET_DPI = 300\n",
    "mat = fitz.Matrix(TARGET_DPI/ 72, TARGET_DPI/ 72)\n",
    "\n",
    "indent_groups = []\n",
    "indent_err = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(word):\n",
    "    \"\"\"\n",
    "    valid words are words that are:\n",
    "    - at least 2 characters\n",
    "        - unless it's x (symbol for hybrid)\n",
    "    \"\"\"\n",
    "    return not bool(re.search(r\"[0-9]+[,.]?\", word)) and (len(word) > 1 or word == 'x' or word == 'X' or word == '×')\n",
    "\n",
    "def preprocessing(page_num):\n",
    "    #group_by_indent\n",
    "    \"\"\"prune out invalid words\"\"\"\n",
    "    page_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    page_df['page_num'] = np.array([page_num]*page_df.shape[0])\n",
    "    page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    page_df = page_df[page_df[\"word\"].apply(valid)].reset_index()\n",
    "    \n",
    "    \"\"\"reset word_no values (useful for cases where word that was originally at 0th index was pruned out\"\"\"\n",
    "    for b in page_df['block_no'].unique():\n",
    "        for l in page_df['line_no'].unique():\n",
    "            page_df.loc[(page_df['line_no'] == l) & (page_df['block_no'] == b), 'word_no'] = np.arange(len(page_df[(page_df['line_no'] == l) & (page_df['block_no'] == b)]['word_no'])).astype(int) #this is slowww\n",
    "\n",
    "    return page_df.reset_index()\n",
    "\n",
    "#https://stackoverflow.com/questions/53468558/adding-image-to-pandas-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genus_blocks(page_df, draw, color = '#6c899e', w = 3):\n",
    "    genus_list = page_df['genus'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for g in genus_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['genus'] == g)]\n",
    "            g_x0 = temp_df['x0'].min()\n",
    "            g_y0 = temp_df['y0'].min()\n",
    "            g_x1 = temp_df['x1'].max()\n",
    "            g_y1 = temp_df['y1'].max()\n",
    "\n",
    "            draw.rectangle((g_x0, g_y0, g_x1, g_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "        \n",
    "def plot_epitet_blocks(page_df, draw, color = '#54081f', w = 2):\n",
    "    epitet_list = page_df['epitet'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for s in epitet_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['epitet'] == s)]\n",
    "            for g in temp_df['genus'].unique():\n",
    "                    \n",
    "                temp_g_df = temp_df[(temp_df['genus']) == g]\n",
    "                s_x0 = temp_g_df['x0'].min()\n",
    "                s_y0 = temp_g_df['y0'].min()\n",
    "                s_x1 = temp_g_df['x1'].max()\n",
    "                s_y1 = temp_g_df['y1'].max()\n",
    "\n",
    "                draw.rectangle((s_x0, s_y0, s_x1, s_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_blocks(page_df, draw, color = '#4a3757', w = 2):\n",
    "    block_list = page_df['block_no'].unique()\n",
    "    for i in block_list:\n",
    "        df_groupped = page_df[page_df['block_no'] == i]\n",
    "        x0_arr = df_groupped['x0'].min()\n",
    "        y0_arr = df_groupped['y0'].min()\n",
    "        x1_arr = df_groupped['x1'].max()\n",
    "        y1_arr = df_groupped['y1'].max()\n",
    "\n",
    "        draw.rectangle((x0_arr, y0_arr, x1_arr, y1_arr), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_author_blocks(page_df, draw, color = '#a3a3a3', w = 1):\n",
    "    epitet_list = page_df['epitet'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for s in epitet_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['epitet'] == s)]\n",
    "            for g in temp_df['genus'].unique():\n",
    "                temp_g_df = temp_df[(temp_df['genus'] == g) & (temp_df['word'] != s)]\n",
    "                a_x0 = temp_g_df['x0'].min()\n",
    "                a_y0 = temp_g_df['y0'].min()\n",
    "                a_x1 = temp_g_df['x1'].max()\n",
    "                a_y1 = temp_g_df['y1'].max()\n",
    "                \n",
    "                draw.rectangle((a_x0, a_y0, a_x1, a_y1), fill=None, outline=ImageColor.getrgb(color), width = w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_genus(word):\n",
    "    \"\"\"\n",
    "    A word in the index might be a genus if it satisfies the following properties:\n",
    "    - letters: french alphabet + at most one hyphen (which is not first or last letter)\n",
    "        - first letter upper case\n",
    "        - all but first lowecase \n",
    "    in regex: ^[A-ZÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]{1}[a-zàâäèéêëîïôœùûüÿç]*[-]?[a-zàâäèéêëîïôœùûüÿç]+$\n",
    "        * based on the current expression it'd also be at least 2 letters long\n",
    "    \"\"\"\n",
    "    regex = r\"^[A-ZÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]{1}[a-zàâäèéêëîïôœùûüÿç]*[-]?[a-zàâäèéêëîïôœùûüÿç]+$\"\n",
    "    return re.search(regex, word)\n",
    "    \n",
    "\n",
    "def is_epithet(word):\n",
    "    \"\"\"\n",
    "    A word in the index might be an epithet if it satisfies the following properties:\n",
    "    - letters: french alphabet + at most one hyphen (which is not first or last letter)\n",
    "        - all letters lowecase \n",
    "    in regex: ^[a-zàâäèéêëîïôœùûüÿç]+[-]?[a-zàâäèéêëîïôœùûüÿç]+$\n",
    "        * based on the current expression it'd also be at least 2 letters long\n",
    "    \"\"\"\n",
    "    regex = r\"^[a-zàâäèéêëîïôœùûüÿç]+[-]?[a-zàâäèéêëîïôœùûüÿç]+$\"\n",
    "    return re.search(regex, word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(page_num, genus = np.NaN, genus_block_no = np.NaN):\n",
    "    def initiate_groups(row):\n",
    "        #return row\n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        word_no = row['word_no']\n",
    "        word = row['word']\n",
    "        alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "        alph_word = ''.join(e for e in word if e.isalpha())\n",
    "        \n",
    "        if row['line_no'] == 0 and (word.lower() == 'nouvelle' or word.lower() == 'flore'):\n",
    "            return \n",
    "        if (word_no == 0) and (not alphnum_word.isnumeric()) and alph_word:\n",
    "            #word_no == 0 => the word is a Family, Genus, Species\n",
    "            new_group = True\n",
    "            for g in indent_groups:\n",
    "                g_arr = np.array(g)[:,0]\n",
    "                if (x_0, y_0, x_1, y_1)[0] <= np.mean(g_arr) + indent_err and (x_0, y_0, x_1, y_1)[0] >= np.mean(g_arr) - indent_err:\n",
    "                    g.append((x_0, y_0, x_1, y_1))\n",
    "                    new_group = False\n",
    "            if new_group:\n",
    "                indent_groups.append([(x_0, y_0, x_1, y_1)])\n",
    "\n",
    "    def get_indent_group(row):\n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        word_no = row['word_no']\n",
    "        word = row['word']\n",
    "        alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "        \n",
    "        if (len(word) > 1) and ((not alphnum_word.isnumeric()) and (word_no == 0)): \n",
    "            for g_i, g in enumerate(indent_groups):\n",
    "                g_arr = np.array(g)[:,0]\n",
    "                if (x_0, y_0, x_1, y_1)[0] <= np.mean(g_arr) + indent_err and (x_0, y_0, x_1, y_1)[0] >= np.mean(g_arr) - indent_err:\n",
    "                    return g_i\n",
    "\n",
    "    def get_col(row): \n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        return int(x_0 > ((x_min + x_max) / 2))\n",
    "\n",
    "    def n_leftmost_indent(indent_groups, n):\n",
    "        indent_means = []\n",
    "        for g_i, g in enumerate(indent_groups):\n",
    "            g_arr = np.array(g)[:,0]\n",
    "            indent_means.append([g_i, np.mean(g_arr)])\n",
    "\n",
    "        n_smallest = indent_means.sort(key = lambda x : x[1])[:n] #n smallest\n",
    "        return [el[0] for el in n_smallest]\n",
    "\n",
    "    def process_col(row):\n",
    "        nonlocal genus\n",
    "        nonlocal x_0, y_0, x_1, y_1 \n",
    "        nonlocal epitet\n",
    "        nonlocal genus_block_no\n",
    "        word_no = row['word_no']\n",
    "        block_no = row['block_no']\n",
    "        line_no = row['line_no']\n",
    "        word = row['word']\n",
    "\n",
    "        row['epitet'] = np.NaN\n",
    "        row['genus'] = np.NaN\n",
    "        \n",
    "        alph_word = ''.join(e for e in word if e.isalpha())\n",
    "\n",
    "        if line_no == 0 and (word.lower() == 'nouvelle' or word.lower() == 'flore'):\n",
    "            return row\n",
    "\n",
    "        if (not (word.isupper() and word_no == 0)) and len(word) > 1  and alph_word:\n",
    "            if word_no == 0: #epitet, or genus\n",
    "                x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "\n",
    "            alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "            if (not alphnum_word.isnumeric()): \n",
    "                if  x_0 <= g_x0 + indent_err and x_0 >= g_x0 - indent_err:\n",
    "                    if word_no == 0:\n",
    "                        genus = word\n",
    "                        row['genus'] = genus\n",
    "                        genus_block_no = row['block_no']\n",
    "                    elif word_no != 0 and line_no == 0 and block_no == genus_block_no: #info on same line as genus\n",
    "                        #epitet = word\n",
    "                        #print(genus, alphnum_word)\n",
    "                        row['epitet'] = np.NaN\n",
    "                        row['genus'] = genus\n",
    "                        #row['author']\"\"\"\n",
    "                        row['sub'] = np.NaN\n",
    "                    else:\n",
    "                        row['epitet'] = epitet\n",
    "                        row['genus'] = genus\n",
    "                        row['sub'] = np.NaN\n",
    "                elif x_0 <= s_x0 + indent_err and x_0 >= s_x0 - indent_err:\n",
    "                    if word_no == 0:\n",
    "                        epitet = word\n",
    "                    row['epitet'] = epitet\n",
    "                    row['genus'] = genus\n",
    "                    row['sub'] = np.NaN\n",
    "                elif word_no == 0 and (word == 'var.' or word == 'subsp.' or word == 'x' or word == 'X'): #assuming at least genus line exists\n",
    "                    row['epitet'] = epitet\n",
    "                    row['genus'] = genus\n",
    "                    row['sub'] = word\n",
    "\n",
    "        return row\n",
    "\n",
    "    #page_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    #page_df['page_num'] = np.array([page_num]*page_df.shape[0])\n",
    "    #page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    \n",
    "    page_df = preprocessing(page_num)\n",
    "    indent_groups = []\n",
    "    indent_err = 15\n",
    "\n",
    "    x_min = page_df['x0'].min()\n",
    "    y_min = page_df['y0'].min()\n",
    "    x_max = page_df['x1'].max()\n",
    "    y_max = page_df['y1'].max()\n",
    "    \n",
    "    page_df.apply(initiate_groups, axis = 1)\n",
    "    page_df['indent_group'] = page_df.apply(get_indent_group, axis = 1)\n",
    "\n",
    "    page_df['col'] = page_df.apply(get_col, axis = 1)\n",
    "    \n",
    "    x_0, y_0, x_1, y_1, epitet = np.NaN, np.NaN, np.NaN, np.NaN, np.NaN\n",
    "    for c in page_df['col'].unique():\n",
    "        \n",
    "        # what if just one largest? what would that even mean? Hm ... (like what if it's all)\n",
    "        col_df = page_df[(page_df['col'] == c)]\n",
    "        col_indent_groups =  list(col_df[~col_df['indent_group'].isnull()]['indent_group'].unique())\n",
    "        #n_leftmost = n_leftmost_indent(col_indent_groups, 2)\n",
    "        #col_df[col_df['indent_group'] == s_indent]\n",
    "        #if len(n_leftmost) == 2:\n",
    "\n",
    "        s_x0, g_x0 = float('inf'), float('inf')\n",
    "        s_indent, g_indent = -1, -1\n",
    "\n",
    "        for g in col_indent_groups:\n",
    "            mean_x0 = col_df[col_df['indent_group'] == g]['x0'].mean()\n",
    "            if g_x0 > mean_x0:\n",
    "                s_indent, g_indent = g_indent, g\n",
    "                s_x0, g_x0 = g_x0, mean_x0 \n",
    "            elif s_x0 > mean_x0: #and g_x0 <= mean_x0\n",
    "                s_indent = g\n",
    "                s_x0 = mean_x0\n",
    "\n",
    "        #if col_df[col_df['indent_group'] == s_indent]['word'].str.contains('var.|subsp.').any():\n",
    "        \n",
    "        #print(genus, s_x0, g_x0)\n",
    "\n",
    "\n",
    "        species_indent_df = col_df[col_df['indent_group'] == s_indent]\n",
    "        if (species_indent_df['word'] == 'var.').any() or (species_indent_df['word'] == 'subsp.').any():\n",
    "            s_x0, g_x0 = g_x0, float('inf')\n",
    "            s_indent, g_indent = g_indent, -1\n",
    "            #print(\"no genus in a column of page\", page_num)\n",
    "        if (s_x0  < g_x0):\n",
    "            s_x0, g_x0 = g_x0, s_x0\n",
    "            s_indent, g_indent = g_indent, s_indent\n",
    "\n",
    "        if s_indent == -1:\n",
    "            s_x0, g_x0 = g_x0, float('inf')\n",
    "            s_indent, g_indent = g_indent, -1\n",
    "\n",
    "        col_df = col_df.apply(process_col, axis = 1)\n",
    "        page_df.loc[col_df.index, ['genus', 'epitet', 'sub']] = col_df.loc[col_df.index, ['genus', 'epitet', 'sub']]\n",
    "        #print(\"g_x0, s_x0, g_indent, s_indent:\", g_x0, s_x0, g_indent, s_indent)\n",
    "    #print(\"genus\", genus)\n",
    "\n",
    "    return page_df, genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author(page_df):\n",
    "    #pruned_df = page_df[(~page_df['genus'].isnull())].reset_index()\n",
    "    epitet_names = page_df[~page_df['epitet'].isnull()]['epitet'].unique()\n",
    "    genus_names = page_df[~page_df['genus'].isnull()]['genus'].unique()\n",
    "    for i in range(len(page_df['x0'])):\n",
    "        word = page_df.loc[i, 'word']\n",
    "        if word in epitet_names:\n",
    "            #print(word, i)\n",
    "            s = page_df.loc[i, 'word']\n",
    "            g = page_df.loc[i, 'genus']\n",
    "            sub_df = page_df[(page_df['genus'] == g) & (page_df['epitet'] == s) & (page_df['word'] != s)]\n",
    "            \n",
    "            merged = sub_df.groupby('epitet')['word'].agg(' '.join).reset_index()\n",
    "            \n",
    "            concat_str = np.NaN\n",
    "            if len(merged.index):\n",
    "                concat_str = merged['word'].item()\n",
    "            \n",
    "            page_df.loc[i, 'author'] = concat_str\n",
    "\n",
    "        if word in genus_names:\n",
    "            g = page_df.loc[i, 'genus']\n",
    "            g_block_no = page_df.loc[i, 'block_no']\n",
    "            sub_df = page_df[(page_df['genus'] == g) & (page_df['block_no'] == g_block_no) & (page_df['word_no'] != 0) & (page_df['line_no'] == 0)]\n",
    "            merged = sub_df.groupby('genus')['word'].agg(' '.join).reset_index()\n",
    "            concat_str = np.NaN\n",
    "            if len(merged.index):\n",
    "                #print(g, word)\n",
    "                concat_str = merged['word'].item()\n",
    "            page_df.loc[i, 'author'] = concat_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [01:10<00:00,  2.50s/it]\n"
     ]
    }
   ],
   "source": [
    "genus = np.NaN\n",
    "result_ims = []\n",
    "df_list = []\n",
    "\n",
    "for page_num in tqdm(index):\n",
    "    page_df, genus = process_df(page_num, genus)\n",
    "    get_author(page_df)\n",
    "    \n",
    "    pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "    image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    plot_genus_blocks(page_df, draw, w = 4)\n",
    "    plot_epitet_blocks(page_df, draw, w = 3)\n",
    "    plot_author_blocks(page_df, draw, w = 2)\n",
    "\n",
    "    df_list.append(page_df)\n",
    "    result_ims.append(image)\n",
    "    #break\n",
    "result_ims[0].save('../output/index/PDF/vol3_with_preprocess.pdf',save_all=True, append_images=result_ims[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, axis = 0)\n",
    "#df.to_csv('../output/index/CSV/vol2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>in_x0</th>\n",
       "      <th>in_y0</th>\n",
       "      <th>in_x1</th>\n",
       "      <th>in_y1</th>\n",
       "      <th>word</th>\n",
       "      <th>block_no</th>\n",
       "      <th>line_no</th>\n",
       "      <th>word_no</th>\n",
       "      <th>page_num</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>indent_group</th>\n",
       "      <th>col</th>\n",
       "      <th>genus</th>\n",
       "      <th>epitet</th>\n",
       "      <th>sub</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>52.320000</td>\n",
       "      <td>492.379181</td>\n",
       "      <td>66.466461</td>\n",
       "      <td>501.812378</td>\n",
       "      <td>var.</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>217.999999</td>\n",
       "      <td>2051.579920</td>\n",
       "      <td>276.943588</td>\n",
       "      <td>2090.884908</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nigella</td>\n",
       "      <td>arvensis</td>\n",
       "      <td>var.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>52.320000</td>\n",
       "      <td>501.979218</td>\n",
       "      <td>66.466461</td>\n",
       "      <td>511.412415</td>\n",
       "      <td>var.</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>217.999999</td>\n",
       "      <td>2091.580073</td>\n",
       "      <td>276.943588</td>\n",
       "      <td>2130.885061</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nigella</td>\n",
       "      <td>arvensis</td>\n",
       "      <td>var.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>52.560001</td>\n",
       "      <td>511.579193</td>\n",
       "      <td>66.367104</td>\n",
       "      <td>521.012390</td>\n",
       "      <td>var.</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>721</td>\n",
       "      <td>219.000006</td>\n",
       "      <td>2131.579971</td>\n",
       "      <td>276.529598</td>\n",
       "      <td>2170.884959</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nigella</td>\n",
       "      <td>arvensis</td>\n",
       "      <td>var.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         in_x0       in_y0      in_x1       in_y1  word  block_no  line_no  \\\n",
       "96   52.320000  492.379181  66.466461  501.812378  var.        30        0   \n",
       "99   52.320000  501.979218  66.466461  511.412415  var.        30        1   \n",
       "102  52.560001  511.579193  66.367104  521.012390  var.        30        2   \n",
       "\n",
       "     word_no  page_num          x0           y0          x1           y1  \\\n",
       "96         0       721  217.999999  2051.579920  276.943588  2090.884908   \n",
       "99         0       721  217.999999  2091.580073  276.943588  2130.885061   \n",
       "102        0       721  219.000006  2131.579971  276.529598  2170.884959   \n",
       "\n",
       "     indent_group  col    genus    epitet   sub author  \n",
       "96            3.0    0  Nigella  arvensis  var.    NaN  \n",
       "99            3.0    0  Nigella  arvensis  var.    NaN  \n",
       "102           3.0    0  Nigella  arvensis  var.    NaN  "
      ]
     },
     "output_type": "unknown"
    }
   ],
   "source": [
    "df[~df['sub'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_pruned_df = df[(~df['author'].isnull()) | (df['word'] == df['genus'])]\n",
    "simple_genus_species_author = author_pruned_df[[\"genus\", \"epitet\", \"author\"]]\n",
    "#simple_genus_species_author.to_csv('../output/index/CSV/vol2_simplified.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}