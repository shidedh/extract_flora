{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import fitz\n",
    "import re\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "import operator\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ploting funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genus_blocks(page_df, draw, color = '#6c899e', w = 3):\n",
    "    try:\n",
    "        genus_list = page_df['draw_genus'].unique()\n",
    "    except:\n",
    "        print(\"no GENUS found\")\n",
    "        return \n",
    "\n",
    "    for g in genus_list:\n",
    "        temp_df = page_df[(page_df['draw_genus'] == g)]\n",
    "        g_x0 = temp_df['x0'].min()\n",
    "        g_y0 = temp_df['y0'].min()\n",
    "        g_x1 = temp_df['x1'].max()\n",
    "        g_y1 = temp_df['y1'].max()\n",
    "\n",
    "        draw.rectangle((g_x0, g_y0, g_x1, g_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "        \n",
    "def plot_epithet_blocks(page_df, draw, color = '#660066', w = 3):\n",
    "    try:\n",
    "        epithet_list = page_df['draw_epithet'].unique()\n",
    "    except:\n",
    "        print(\"no EPITHET found\")\n",
    "        return \n",
    "    \n",
    "    for e in epithet_list:\n",
    "        temp_df = page_df[(page_df['draw_epithet'] == e)]\n",
    "        e_x0 = temp_df['x0'].min()\n",
    "        e_y0 = temp_df['y0'].min()\n",
    "        e_x1 = temp_df['x1'].max()\n",
    "        e_y1 = temp_df['y1'].max()\n",
    "\n",
    "        draw.rectangle((e_x0, e_y0, e_x1, e_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_author_blocks(page_df, draw, color = '#a3a3a3', w = 1):\n",
    "    try:\n",
    "        author_list = page_df['draw_author'].unique()\n",
    "    except:\n",
    "        print(\"no AUTHOR found\")\n",
    "        return \n",
    "\n",
    "    for a in author_list:\n",
    "        temp_df = page_df[(page_df['draw_author'] == a)]\n",
    "        e_x0 = temp_df['x0'].min()\n",
    "        e_y0 = temp_df['y0'].min()\n",
    "        e_x1 = temp_df['x1'].max()\n",
    "        e_y1 = temp_df['y1'].max()\n",
    "\n",
    "        draw.rectangle((e_x0, e_y0, e_x1, e_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_infra_blocks(page_df, draw, color = '#ff6289', w = 1):\n",
    "    try:\n",
    "        infra_list = page_df['draw_infra'].unique()\n",
    "    except:\n",
    "        print(\"no INFRA Spp. found\")\n",
    "        return \n",
    "\n",
    "    for infra_spp in infra_list:\n",
    "        temp_df = page_df[(page_df['draw_infra'] == infra_spp)]\n",
    "        e_x0 = temp_df['x0'].min()\n",
    "        e_y0 = temp_df['y0'].min()\n",
    "        e_x1 = temp_df['x1'].max()\n",
    "        e_y1 = temp_df['y1'].max()\n",
    "\n",
    "        draw.rectangle((e_x0, e_y0, e_x1, e_y1), fill=None, outline=ImageColor.getrgb(color), width = w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Vol3 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = \"../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 3.pdf\"\n",
    "doc = fitz.open(pdf_dir)\n",
    "pages = [doc[i] for i in range(doc.pageCount)]\n",
    "index = list(range(555, 583))\n",
    "\n",
    "TARGET_DPI = 300\n",
    "mat = fitz.Matrix(TARGET_DPI/ 72, TARGET_DPI/ 72)\n",
    "\n",
    "indent_groups = []\n",
    "indent_err = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regex based boolean functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(word):\n",
    "    \"\"\"\n",
    "    valid words are words that are:\n",
    "    - at least 2 characters\n",
    "        - unless it's x (symbol for hybrid)\n",
    "    \"\"\"\n",
    "    return (not bool(re.search(r\"[0-9]+[,.]?\", word))) and (len(word) > 1 or word == 'x' or word == 'X' or word == '×' or word == r'\\u00D7')\n",
    "    \n",
    "def is_genus(word):\n",
    "    \"\"\"\n",
    "    A word in the index might be a genus if it satisfies the following properties:\n",
    "    - letters: french alphabet + at most one hyphen (which is not first or last letter)\n",
    "        - first letter upper case\n",
    "        - all but first lowecase \n",
    "    in regex: ^[A-ZÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]{1}[a-zàâäèéêëîïôœùûüÿç]*[-]?[a-zàâäèéêëîïôœùûüÿç]+$ #ignoring strict beggining and end cause of noise\n",
    "        * based on the current expression it'd also be at least 2 letters long\n",
    "    \"\"\"\n",
    "    regex = r\"[A-ZÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ\\u00D7]{1}[a-zàâäèéêëîïôœùûüÿç]*[-]?[a-zàâäèéêëîïôœùûüÿç]+\"\n",
    "    return re.search(regex, word)\n",
    "    \n",
    "\n",
    "def is_epithet(word):\n",
    "    \"\"\"\n",
    "    A word in the index might be an epithet if it satisfies the following properties:\n",
    "    - letters: french alphabet + at most one hyphen (which is not first or last letter)\n",
    "        - all letters lowecase \n",
    "    in regex: ^[a-zàâäèéêëîïôœùûüÿç]+[-]?[a-zàâäèéêëîïôœùûüÿç]+$ #ignoring strict beggining and end cause of noise \n",
    "        * based on the current expression it'd also be at least 2 letters long\n",
    "    \"\"\"\n",
    "    regex = r\"[a-zàâäèéêëîïôœùûüÿç\\u00D7]+[-]?[a-zàâäèéêëîïôœùûüÿç]+\"\n",
    "    return re.search(regex, word)\n",
    "    \n",
    "def is_hybrid(word):\n",
    "    regex = r\"^(([Xx\\u00D7])|([Xx\\u00D7]\\.))$\"\n",
    "    return re.search(regex, word)\n",
    "\n",
    "def is_infra(word):\n",
    "    regex = r\"^(var\\.)|(subsp\\.)\"\n",
    "    return re.search(regex, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pre-processing func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(page_num, indent_err = 15):\n",
    "    \n",
    "    #initiate dataframe\n",
    "    page_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    \n",
    "    #add page number to dataframe\n",
    "    page_df['page_num'] = np.array([page_num]*page_df.shape[0])\n",
    "    #initiate all columns that will be added\n",
    "    page_df['genus'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_genus'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['epithet'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_epithet'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['author'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_author'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['infra'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['draw_infra'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['taxon rank'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    page_df['error_check'] = np.array([np.NaN]*page_df.shape[0])\n",
    "    #updating coordinates to represent target DPI\n",
    "    page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    #get x corner coordinates \n",
    "    x_min = page_df['x0'].min()\n",
    "    x_max = page_df['x1'].max()\n",
    "\n",
    "    #invalid words dataframe -- for error checking\n",
    "    pruned_words_df = page_df[~page_df[\"word\"].apply(valid)].reset_index()\n",
    "    #prune out invalid words (based on function valid)\n",
    "    page_df = page_df[page_df[\"word\"].apply(valid)].reset_index()\n",
    "    \n",
    "    indent_groups = []\n",
    "    blocks = page_df['block_no'].unique()\n",
    "    for b in blocks:\n",
    "        lines = page_df[page_df['block_no'] == b]['line_no'].unique()\n",
    "        for l in lines:\n",
    "            #reset word_no values (useful for cases where word that was originally at 0th index was pruned out)\n",
    "            cond = (page_df['line_no'] == l) & (page_df['block_no'] == b)\n",
    "            num_words = len(page_df[cond]['word_no'])\n",
    "            page_df.loc[cond, 'word_no'] = np.arange(num_words).astype(int) #this is slowww\n",
    "            #set column number (0 or 1)\n",
    "            x_0 = page_df[cond]['x0'].min()\n",
    "            #THIS DOESN'T WORK AAAA -- issue was with line no thing\n",
    "            if not np.isnan(x_0):\n",
    "                page_df.loc[cond, 'col_no'] = np.array([int(x_0 > ((x_min + x_max) / 2))]*num_words).astype(int)\n",
    "\n",
    "                #initiate indent groups -- only first word should get an indent_group value \n",
    "                new_group = True\n",
    "                for g_i in range(len(indent_groups)):\n",
    "                    g = indent_groups[g_i]\n",
    "                    g_arr = np.array(g)\n",
    "                    if x_0 <= np.mean(g_arr) + indent_err and x_0 >= np.mean(g_arr) - indent_err:\n",
    "                        g.append(x_0)\n",
    "                        new_group = False\n",
    "                        page_df.loc[cond, 'indent_group'] = np.array([g_i]*num_words).astype(int)\n",
    "                if new_group:\n",
    "                    indent_groups.append([x_0])\n",
    "                    g_i = len(indent_groups) - 1\n",
    "                    page_df.loc[cond, 'indent_group'] = np.array([g_i]*num_words).astype(int)\n",
    "\n",
    "\n",
    "    #return updated page_df, pruned_words_df, indent groups\n",
    "    return page_df.reset_index(), pruned_words_df, indent_groups\n",
    "\n",
    "#https://stackoverflow.com/questions/53468558/adding-image-to-pandas-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:14<00:00,  1.89it/s]\n"
     ]
    }
   ],
   "source": [
    "genus = np.NaN\n",
    "df_dict = {}\n",
    "pruned_dict = {}\n",
    "\n",
    "for page_num in tqdm(index):\n",
    "    page_df, pruned_df, indent_group = preprocessing(page_num)\n",
    "    df_dict[page_num] = page_df\n",
    "    pruned_dict[page_num] = pruned_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding indentations associated with genus, epithet, infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['genus', 'epithet', 'infra', 'author', 'misc.']\n",
    "def n_leftmost_indent(df, n):\n",
    "    \"\"\"return a tuple with at most 3 elements each element itself is a tuple containing indent group, mean, group len\"\"\"\n",
    "    indent_groups = [(g, df[(df['indent_group'] == g) & (df['word_no'] == 0)]['x0'].mean(), len(df[(df['indent_group'] == g) & (df['word_no'] == 0)]['x0'])) for g in df['indent_group'].unique()]\n",
    "    indent_groups.sort(key = lambda x : x[1])\n",
    "    return indent_groups[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genusEpithetInfra_indent(col_df):\n",
    "    leftmost_3_indents = n_leftmost_indent(col_df, 3) \n",
    "    min_gap = 25\n",
    "    max_gap = 50\n",
    "\n",
    "    # possibly not specific enough\n",
    "    # first identifying indent based don distance from one another only\n",
    "    if len(leftmost_3_indents) == 3:\n",
    "        if leftmost_3_indents[0][1] < max_gap:\n",
    "            leftmost_3_indents = leftmost_3_indents[1:]\n",
    "        elif ((leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) > max_gap or \\\n",
    "            (leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) < min_gap): #comparing first two (if satisfied last two will be checked in next if block)\n",
    "            leftmost_3_indents = [max(leftmost_3_indents[1:], key = lambda x : x[2])] + [leftmost_3_indents[2]]\n",
    "        elif (leftmost_3_indents[2][1] - leftmost_3_indents[1][1]) > max_gap or \\\n",
    "            (leftmost_3_indents[2][1] - leftmost_3_indents[1][1]) < min_gap: #comparing last two\n",
    "            leftmost_3_indents = [leftmost_3_indents[0]] + [max(leftmost_3_indents[1:], key = lambda x : x[2])]\n",
    "\n",
    "    if len(leftmost_3_indents) == 2:\n",
    "        if leftmost_3_indents[0][1] < max_gap:\n",
    "            leftmost_3_indents = leftmost_3_indents[1]\n",
    "        elif (leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) > max_gap or (leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) < min_gap:\n",
    "            leftmost_3_indents = [max(leftmost_3_indents, key = lambda x : x[2])]\n",
    "\n",
    "    has_genus, has_epithet, has_infra = False, False, False\n",
    "    genus_indent, epithet_indent, infra_indent = -1, -1, -1\n",
    "    if len(leftmost_3_indents) == 3:\n",
    "        has_genus, has_epithet, has_infra = True, True, True\n",
    "        genus_indent, epithet_indent, infra_indent = [el[0] for el in leftmost_3_indents]\n",
    "    elif len(leftmost_3_indents) == 2:\n",
    "        if col_df[col_df['indent_group'] == leftmost_3_indents[1][0]]['word'].apply(is_infra).any():\n",
    "            has_genus, has_epithet, has_infra = False, True, True\n",
    "            epithet_indent, infra_indent = [el[0] for el in leftmost_3_indents]\n",
    "        else:\n",
    "            has_genus, has_epithet, has_infra = True, True, False\n",
    "            genus_indent, epithet_indent = [el[0] for el in leftmost_3_indents]\n",
    "    elif len(leftmost_3_indents) == 2: \n",
    "        has_genus, has_epithet, has_infra = False, True, False\n",
    "        epithet_indent = leftmost_3_indents[0][0]\n",
    "\n",
    "    return genus_indent, epithet_indent, infra_indent, leftmost_3_indents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing column dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_col(col_df, genus, epithet, draw_genus, draw_epithet, draw_infra = np.NaN):\n",
    "    genus_indent, epithet_indent, infra_indent, indent_3_left = get_genusEpithetInfra_indent(col_df)\n",
    "    blocks = col_df['block_no'].unique()\n",
    "    start_word_cond = -1 \n",
    "    author = ''\n",
    "    #draw_infra = np.NaN\n",
    "    \n",
    "    for b in blocks:\n",
    "        lines = col_df[col_df['block_no'] == b]['line_no'].unique()\n",
    "        for l in lines:\n",
    "            cond = (col_df['line_no'] == l) & (col_df['block_no'] == b)\n",
    "            words = col_df[cond]['word_no'].unique()\n",
    "            process_hybrid = False\n",
    "            process_infra = False\n",
    "            \n",
    "            col_df = col_df.copy()\n",
    "            for w in words:\n",
    "                word_cond = (col_df['line_no'] == l) & (col_df['block_no'] == b) & (col_df['word_no'] == w) \n",
    "                word = col_df[word_cond]['word'].item()\n",
    "                #print(word)\n",
    "            \n",
    "                if w == 0:\n",
    "                    infra = ''\n",
    "                    if author != '':\n",
    "                        col_df.loc[start_word_cond, 'author'] = author\n",
    "                        author = ''\n",
    "                    \n",
    "                    start_word_cond = word_cond\n",
    "                    start_l = l \n",
    "                    start_b = b \n",
    "\n",
    "                    indent_group = col_df[word_cond]['indent_group'].item()\n",
    "                    \n",
    "                    if is_hybrid(word):\n",
    "                        process_hybrid = True\n",
    "                        misc = word\n",
    "                        author = ''\n",
    "                        #col_df.loc[start_word_cond, 'misc.'] = misc\n",
    "                    #now only gotta say INDENT AND satisfies these paterns\n",
    "                    #print(indent_group, genus_indent)\n",
    "                    else: \n",
    "                        if indent_group == genus_indent:\n",
    "                            if not ''.join(e for e in word if e.isalpha()).isupper():\n",
    "                                genus = word\n",
    "                                misc = ''\n",
    "                                author = ''\n",
    "                                infra = ''\n",
    "                                epithet = ''\n",
    "                                draw_genus = genus\n",
    "                                col_df.loc[start_word_cond, 'genus'] = genus\n",
    "                                col_df.loc[start_word_cond, 'taxon rank'] = 'genus'\n",
    "                                if not is_genus(word):\n",
    "                                    col_df.loc[start_word_cond, 'error_check'] = True\n",
    "                                col_df.loc[word_cond, 'draw_genus'] = draw_genus\n",
    "                                \n",
    "                            else: \n",
    "                                genus = ''\n",
    "                                misc = ''\n",
    "                                author = ''\n",
    "                                infra = ''\n",
    "                                epithet = ''\n",
    "                                draw_genus = np.NaN\n",
    "                        elif indent_group == epithet_indent and not ''.join(e for e in word if e.isalpha()).isupper():\n",
    "                            epithet = word\n",
    "                            misc = ''\n",
    "                            infra = ''\n",
    "                            author = ''\n",
    "                            col_df.loc[start_word_cond, 'genus'] = genus\n",
    "                            col_df.loc[start_word_cond, 'epithet'] = epithet\n",
    "                            col_df.loc[start_word_cond, 'taxon rank'] = 'species'\n",
    "                            if not is_epithet(word):\n",
    "                                col_df.loc[start_word_cond, 'error_check'] = True\n",
    "                            draw_epithet = str(genus) + '_' + str(epithet) +'_' + str(start_b) + '_' + str(start_l)\n",
    "                            col_df.loc[word_cond, 'draw_genus'] = draw_genus\n",
    "                            col_df.loc[word_cond, 'draw_epithet'] = draw_epithet\n",
    "                        \n",
    "\n",
    "                        elif indent_group == infra_indent:\n",
    "                            process_infra = True\n",
    "                            misc = word\n",
    "                            author = ''\n",
    "                            #col_df.loc[start_word_cond, 'misc.'] = misc\n",
    "                            if not (is_infra(word) or is_hybrid(word)):\n",
    "                                col_df.loc[start_word_cond, 'error_check'] = True\n",
    "                    \n",
    "                elif process_infra:\n",
    "                    start_word_cond = word_cond\n",
    "                    start_l = l \n",
    "                    start_b = b \n",
    "                    infra = word \n",
    "                    col_df.loc[start_word_cond, 'genus'] = genus\n",
    "                    col_df.loc[start_word_cond, 'epithet'] = epithet\n",
    "                    col_df.loc[start_word_cond, 'infra'] = infra\n",
    "                    #col_df.loc[start_word_cond, 'misc.'] = misc\n",
    "                    col_df.loc[start_word_cond, 'taxon rank'] = misc\n",
    "                    draw_infra = str(infra) + '_'+str(start_b)+'_'+str(start_l)\n",
    "                    process_infra = False\n",
    "                    col_df.loc[word_cond, 'draw_genus'] = draw_genus\n",
    "                    col_df.loc[word_cond, 'draw_epithet'] = draw_epithet\n",
    "                    col_df.loc[word_cond, 'draw_infra'] = draw_infra\n",
    "                    \n",
    "                elif process_hybrid:\n",
    "                    start_word_cond = word_cond\n",
    "                    start_l = l \n",
    "                    start_b = b \n",
    "                    if indent_group == genus_indent:\n",
    "                        genus = word\n",
    "                        epithet = ''\n",
    "                        infra = ''\n",
    "                        author = ''\n",
    "                        draw_genus = genus\n",
    "                        col_df.loc[start_word_cond, 'genus'] = genus\n",
    "                        col_df.loc[start_word_cond, 'taxon rank'] = 'genus - hybrid'\n",
    "                        if not is_genus(word):\n",
    "                            col_df.loc[start_word_cond, 'error_check'] = True\n",
    "                        col_df.loc[word_cond, 'draw_genus'] = draw_genus\n",
    "                            \n",
    "                    elif indent_group == epithet_indent:\n",
    "                        epithet = word\n",
    "                        author = ''\n",
    "                        infra = ''\n",
    "                        col_df.loc[start_word_cond, 'genus'] = genus\n",
    "                        col_df.loc[start_word_cond, 'epithet'] = epithet\n",
    "                        col_df.loc[start_word_cond, 'taxon rank'] = 'species - hybrid'\n",
    "                        draw_epithet = str(genus) + '_' + str(epithet) +'_' + str(start_b) + '_' + str(start_l)\n",
    "                        if not is_epithet(word):\n",
    "                            col_df.loc[start_word_cond, 'error_check'] = True\n",
    "                        col_df.loc[word_cond, 'draw_genus'] = draw_genus\n",
    "                        col_df.loc[word_cond, 'draw_epithet'] = draw_epithet\n",
    "                    elif indent_group == infra_indent:\n",
    "                        infra = word\n",
    "                        col_df.loc[start_word_cond, 'genus'] = genus\n",
    "                        col_df.loc[start_word_cond, 'epithet'] = epithet\n",
    "                        col_df.loc[start_word_cond, 'infra'] = infra\n",
    "                        col_df.loc[start_word_cond, 'taxon rank'] = 'hybrid'\n",
    "                        col_df.loc[word_cond, 'draw_genus'] = draw_genus\n",
    "                        col_df.loc[word_cond, 'draw_epithet'] = draw_epithet\n",
    "                        col_df.loc[word_cond, 'draw_infra'] = draw_infra\n",
    "                    #col_df.loc[start_word_cond, 'misc.'] = 'x'\n",
    "                    process_hybrid = False\n",
    "                else:\n",
    "                    author = author + word + ' '\n",
    "                    col_df.loc[word_cond, 'draw_author'] = 'author_'+str(start_b)+'_'+str(start_l)\n",
    "                    #col_df.loc[word_cond, 'draw_genus'] = draw_genus\n",
    "                    #if epithet:\n",
    "                    #    col_df.loc[word_cond, 'draw_epithet'] = draw_epithet\n",
    "                    #if infra: \n",
    "                    #    col_df.loc[word_cond, 'draw_infra'] = draw_infra\n",
    "\n",
    "    #Last author\n",
    "    if author != '':\n",
    "        col_df.loc[start_word_cond, 'author'] = author\n",
    "    \n",
    "    return col_df, genus, epithet, draw_genus, draw_epithet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:45<00:00,  1.64s/it]\n"
     ]
    }
   ],
   "source": [
    "genus = np.NaN\n",
    "epithet = np.NaN\n",
    "draw_genus = np.NaN\n",
    "draw_epithet = np.NaN\n",
    "result_ims = []\n",
    "df_list = []\n",
    "\n",
    "for page_num in tqdm(index):\n",
    "    #process the pre-processed dfs\n",
    "    page_df = df_dict[page_num]\n",
    "    \n",
    "    #for drawing\n",
    "    pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "    image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    #processing each column\n",
    "    for c in page_df['col_no'].unique():\n",
    "        col_df = page_df[page_df['col_no'] == c]\n",
    "        col_df, genus, epithet, draw_genus, draw_epithet = process_col(col_df, genus, epithet, draw_genus, draw_epithet)\n",
    "        df_list.append(col_df)\n",
    "\n",
    "        #drawing boxes in each column\n",
    "        plot_genus_blocks(col_df, draw)\n",
    "        plot_epithet_blocks(col_df, draw)\n",
    "        plot_author_blocks(col_df, draw)\n",
    "        plot_infra_blocks(col_df, draw)\n",
    "\n",
    "    result_ims.append(image)\n",
    "\n",
    "TIME_STR = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%p\")\n",
    "result_ims[0].save('../output/index/PDF/vol3_index_reverted_ROI'+TIME_STR+'.pdf',save_all=True, append_images=result_ims[1:])\n",
    "\n",
    "df = pd.concat(df_list, axis = 0)\n",
    "df.to_html('../output/index/html/vol3_index_reverted'+TIME_STR+'.html')\n",
    "df.to_csv('../output/index/CSV/vol3_index_reverted'+TIME_STR+'.csv', index = False)\n",
    "\n",
    "pruned = df[(~df['genus'].isnull())]\n",
    "pruned = pruned[[\"page_num\", \"genus\", \"epithet\", \"infra\" ,\"author\", \"taxon rank\"]]\n",
    "pruned.to_csv('../output/index/CSV/vol3_index_reverted_pruned'+TIME_STR+'.csv', index = False)\n",
    "pruned.to_html('../output/index/html/vol3_index_reverted_pruned'+TIME_STR+'.html')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}