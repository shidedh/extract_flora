{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import fitz\n",
    "import re\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "import operator\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genus_blocks(page_df, draw, color = '#6c899e', w = 3):\n",
    "    genus_list = page_df['genus'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for g in genus_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['genus'] == g)]\n",
    "            g_x0 = temp_df['x0'].min()\n",
    "            g_y0 = temp_df['y0'].min()\n",
    "            g_x1 = temp_df['x1'].max()\n",
    "            g_y1 = temp_df['y1'].max()\n",
    "\n",
    "            draw.rectangle((g_x0, g_y0, g_x1, g_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "        \n",
    "def plot_epitet_blocks(page_df, draw, color = '#54081f', w = 2):\n",
    "    epitet_list = page_df['epitet'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for s in epitet_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['epitet'] == s)]\n",
    "            for g in temp_df['genus'].unique():\n",
    "                    \n",
    "                temp_g_df = temp_df[(temp_df['genus']) == g]\n",
    "                s_x0 = temp_g_df['x0'].min()\n",
    "                s_y0 = temp_g_df['y0'].min()\n",
    "                s_x1 = temp_g_df['x1'].max()\n",
    "                s_y1 = temp_g_df['y1'].max()\n",
    "\n",
    "                draw.rectangle((s_x0, s_y0, s_x1, s_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_blocks(page_df, draw, color = '#4a3757', w = 2):\n",
    "    block_list = page_df['block_no'].unique()\n",
    "    for i in block_list:\n",
    "        df_groupped = page_df[page_df['block_no'] == i]\n",
    "        x0_arr = df_groupped['x0'].min()\n",
    "        y0_arr = df_groupped['y0'].min()\n",
    "        x1_arr = df_groupped['x1'].max()\n",
    "        y1_arr = df_groupped['y1'].max()\n",
    "\n",
    "        draw.rectangle((x0_arr, y0_arr, x1_arr, y1_arr), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_author_blocks(page_df, draw, color = '#a3a3a3', w = 1):\n",
    "    epitet_list = page_df['epitet'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for s in epitet_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['epitet'] == s)]\n",
    "            for g in temp_df['genus'].unique():\n",
    "                temp_g_df = temp_df[(temp_df['genus'] == g) & (temp_df['word'] != s)]\n",
    "                a_x0 = temp_g_df['x0'].min()\n",
    "                a_y0 = temp_g_df['y0'].min()\n",
    "                a_x1 = temp_g_df['x1'].max()\n",
    "                a_y1 = temp_g_df['y1'].max()\n",
    "                \n",
    "                draw.rectangle((a_x0, a_y0, a_x1, a_y1), fill=None, outline=ImageColor.getrgb(color), width = w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regex based boolean functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(word):\n",
    "    \"\"\"\n",
    "    valid words are words that are:\n",
    "    - at least 2 characters\n",
    "        - unless it's x (symbol for hybrid)\n",
    "    \"\"\"\n",
    "    return (not bool(re.search(r\"[0-9]+[,.]?\", word))) and (len(word) > 1 or word == 'x' or word == 'X' or word == '×' or word == r'\\u00D7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_genus(word):\n",
    "    \"\"\"\n",
    "    A word in the index might be a genus if it satisfies the following properties:\n",
    "    - letters: french alphabet + at most one hyphen (which is not first or last letter)\n",
    "        - first letter upper case\n",
    "        - all but first lowecase \n",
    "    in regex: ^[A-ZÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]{1}[a-zàâäèéêëîïôœùûüÿç]*[-]?[a-zàâäèéêëîïôœùûüÿç]+$ #ignoring strict beggining and end cause of noise\n",
    "        * based on the current expression it'd also be at least 2 letters long\n",
    "    \"\"\"\n",
    "    regex = r\"[A-ZÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ\\u00D7]{1}[a-zàâäèéêëîïôœùûüÿç]*[-]?[a-zàâäèéêëîïôœùûüÿç]+\"\n",
    "    return re.search(regex, word)\n",
    "    \n",
    "\n",
    "def is_epithet(word):\n",
    "    \"\"\"\n",
    "    A word in the index might be an epithet if it satisfies the following properties:\n",
    "    - letters: french alphabet + at most one hyphen (which is not first or last letter)\n",
    "        - all letters lowecase \n",
    "    in regex: ^[a-zàâäèéêëîïôœùûüÿç]+[-]?[a-zàâäèéêëîïôœùûüÿç]+$ #ignoring strict beggining and end cause of noise \n",
    "        * based on the current expression it'd also be at least 2 letters long\n",
    "    \"\"\"\n",
    "    regex = r\"[a-zàâäèéêëîïôœùûüÿç\\u00D7]+[-]?[a-zàâäèéêëîïôœùûüÿç]+\"\n",
    "    return re.search(regex, word)\n",
    "    \n",
    "def is_hybrid(word):\n",
    "    regex = r\"^(([Xx\\u00D7])|([Xx\\u00D7]\\.))$\"\n",
    "    return re.search(regex, word)\n",
    "\n",
    "def is_infra(word):\n",
    "    regex = r\"^(var\\.)|(subsp\\.)\"\n",
    "    return re.search(regex, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(pages, page_num, indent_err = 15):\n",
    "    \n",
    "    #initiate dataframe\n",
    "    page_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    \n",
    "    #add page number to dataframe\n",
    "    page_df['page_num'] = np.array([page_num]*page_df.shape[0])\n",
    "    #updating coordinates to represent target DPI\n",
    "    page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    #get x corner coordinates \n",
    "    x_min = page_df['x0'].min()\n",
    "    x_max = page_df['x1'].max()\n",
    "\n",
    "    #invalid words dataframe -- for error checking\n",
    "    pruned_words_df = page_df[~page_df[\"word\"].apply(valid)].reset_index()\n",
    "    #prune out invalid words (based on function valid)\n",
    "    page_df = page_df[page_df[\"word\"].apply(valid)].reset_index()\n",
    "    \n",
    "    indent_groups = []\n",
    "    blocks = page_df['block_no'].unique()\n",
    "    for b in blocks:\n",
    "        lines = page_df[page_df['block_no'] == b]['line_no'].unique()\n",
    "        for l in lines:\n",
    "            #reset word_no values (useful for cases where word that was originally at 0th index was pruned out)\n",
    "            cond = (page_df['line_no'] == l) & (page_df['block_no'] == b)\n",
    "            num_words = len(page_df[cond]['word_no'])\n",
    "            page_df.loc[cond, 'word_no'] = np.arange(num_words).astype(int) #this is slowww\n",
    "            #set column number (0 or 1)\n",
    "            x_0 = page_df[cond]['x0'].min()\n",
    "            #THIS DOESN'T WORK AAAA -- issue was with line no thing\n",
    "            if not np.isnan(x_0):\n",
    "                page_df.loc[cond, 'col_no'] = np.array([int(x_0 > ((x_min + x_max) / 2))]*num_words).astype(int)\n",
    "\n",
    "                #initiate indent groups -- only first word should get an indent_group value \n",
    "                new_group = True\n",
    "                for g_i in range(len(indent_groups)):\n",
    "                    g = indent_groups[g_i]\n",
    "                    g_arr = np.array(g)\n",
    "                    if x_0 <= np.mean(g_arr) + indent_err and x_0 >= np.mean(g_arr) - indent_err:\n",
    "                        g.append(x_0)\n",
    "                        new_group = False\n",
    "                        page_df.loc[cond, 'indent_group'] = np.array([g_i]*num_words).astype(int)\n",
    "                if new_group:\n",
    "                    indent_groups.append([x_0])\n",
    "                    g_i = len(indent_groups) - 1\n",
    "                    page_df.loc[cond, 'indent_group'] = np.array([g_i]*num_words).astype(int)\n",
    "\n",
    "\n",
    "    #return updated page_df, pruned_words_df, indent groups\n",
    "    return page_df.reset_index(), pruned_words_df, indent_groups\n",
    "\n",
    "#https://stackoverflow.com/questions/53468558/adding-image-to-pandas-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vol1 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = \"../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 1.pdf\"\n",
    "doc = fitz.open(pdf_dir)\n",
    "pages = [doc[i] for i in range(doc.pageCount)]\n",
    "index = range(616, 639)\n",
    "\n",
    "TARGET_DPI = 300\n",
    "mat = fitz.Matrix(TARGET_DPI/ 72, TARGET_DPI/ 72)\n",
    "\n",
    "indent_groups = []\n",
    "indent_err = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(page_num, genus = np.NaN):\n",
    "    def initiate_groups(row):\n",
    "        #return row\n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        word_no = row['word_no']\n",
    "        word = row['word']\n",
    "        alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "        \n",
    "        if (word_no == 0) and (not alphnum_word.isnumeric()):\n",
    "            #word_no == 0 => the word is a Family, Genus, Species\n",
    "            new_group = True\n",
    "            for g in indent_groups:\n",
    "                g_arr = np.array(g)[:,0]\n",
    "                if (x_0, y_0, x_1, y_1)[0] <= np.mean(g_arr) + indent_err and (x_0, y_0, x_1, y_1)[0] >= np.mean(g_arr) - indent_err:\n",
    "                    g.append((x_0, y_0, x_1, y_1))\n",
    "                    new_group = False\n",
    "            if new_group:\n",
    "                indent_groups.append([(x_0, y_0, x_1, y_1)])\n",
    "\n",
    "    def get_indent_group(row):\n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        word_no = row['word_no']\n",
    "        word = row['word']\n",
    "        alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "        \n",
    "        if (len(word) > 1) and ((not alphnum_word.isnumeric()) and (word_no == 0)): \n",
    "            for g_i, g in enumerate(indent_groups):\n",
    "                g_arr = np.array(g)[:,0]\n",
    "                if (x_0, y_0, x_1, y_1)[0] <= np.mean(g_arr) + indent_err and (x_0, y_0, x_1, y_1)[0] >= np.mean(g_arr) - indent_err:\n",
    "                    return g_i\n",
    "\n",
    "    def get_col(row): \n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        return int(x_0 > ((x_min + x_max) / 2))\n",
    "\n",
    "    def process_col(row):\n",
    "        nonlocal genus\n",
    "        nonlocal x_0, y_0, x_1, y_1 \n",
    "        nonlocal epitet\n",
    "        word_no = row['word_no']\n",
    "        word = row['word']\n",
    "        \n",
    "        alph_word = ''.join(e for e in word if e.isalpha())\n",
    "\n",
    "        if (not (word.isupper() and word_no == 0)):\n",
    "            if word_no == 0: #epitet, or genus\n",
    "                x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "                \n",
    "            alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "            if (not alphnum_word.isnumeric()): \n",
    "                if  x_0 <= g_x0 + indent_err and x_0 >= g_x0 - indent_err:\n",
    "                    if word_no == 0:\n",
    "                        genus = word\n",
    "                        row['genus'] = genus\n",
    "                    elif word_no == 1:\n",
    "                        epitet = word\n",
    "                        row['epitet'] = epitet\n",
    "                        row['genus'] = genus\n",
    "                    else:\n",
    "                        row['epitet'] = epitet\n",
    "                        row['genus'] = genus\n",
    "                elif x_0 <= s_x0 + indent_err and x_0 >= s_x0 - indent_err:\n",
    "                    if word_no == 0:\n",
    "                        epitet = word\n",
    "                    row['epitet'] = epitet\n",
    "                    row['genus'] = genus\n",
    "        return row\n",
    "\n",
    "    #page_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    #page_df['page_num'] = np.array([page_num]*page_df.shape[0])\n",
    "    #page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    page_df, pruned_words_df, indent_groups  = preprocessing(pages, page_num)\n",
    "    #page_df.reset_index(), pruned_words_df, indent_groups\n",
    "    \n",
    "    #indent_groups = []\n",
    "    #indent_err = 15\n",
    "\n",
    "    x_min = page_df['x0'].min()\n",
    "    y_min = page_df['y0'].min()\n",
    "    x_max = page_df['x1'].max()\n",
    "    y_max = page_df['y1'].max()\n",
    "    \n",
    "    #page_df.apply(initiate_groups, axis = 1)\n",
    "    #page_df['indent_group'] = page_df.apply(get_indent_group, axis = 1)\n",
    "\n",
    "    page_df['col'] = page_df.apply(get_col, axis = 1)\n",
    "    \n",
    "    x_0, y_0, x_1, y_1, epitet = np.NaN, np.NaN, np.NaN, np.NaN, np.NaN\n",
    "    for c in page_df['col'].unique():\n",
    "        \n",
    "        # what if just one largest? what would that even mean? Hm ... (like what if it's all)\n",
    "        col_df = page_df[(page_df['col'] == c)]\n",
    "\n",
    "        try:\n",
    "            two_largest = col_df['indent_group'].value_counts().nlargest(2)\n",
    "            \n",
    "            s_indent, g_indent = two_largest.index[0], two_largest.index[1]\n",
    "            s_col_df = col_df[col_df['indent_group'] == s_indent]\n",
    "            g_col_df = col_df[col_df['indent_group'] == g_indent]\n",
    "            s_x0 = s_col_df['x0'].mean()\n",
    "            g_x0 = g_col_df['x0'].mean()\n",
    "            if g_x0 > s_x0:\n",
    "                s_col_df, g_col_df = g_col_df, s_col_df\n",
    "        except:\n",
    "            s_indent = col_df['indent_group'].value_counts().nlargest(1)\n",
    "            s_x0 = s_indent.index[0]\n",
    "            g_x0 = float('inf')\n",
    "        col_df = col_df.apply(process_col, axis = 1)\n",
    "        page_df.loc[col_df.index, ['genus', 'epitet']] = col_df.loc[col_df.index, ['genus', 'epitet']]\n",
    "        \n",
    "    return page_df, genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(page_num, genus = np.NaN, genus_block_no = np.NaN):\n",
    "    def initiate_groups(row):\n",
    "        #return row\n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        word_no = row['word_no']\n",
    "        word = row['word']\n",
    "        alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "        alph_word = ''.join(e for e in word if e.isalpha())\n",
    "        \n",
    "        if row['line_no'] == 0 and (word.lower() == 'nouvelle' or word.lower() == 'flore'):\n",
    "            return \n",
    "        if (word_no == 0) and (not alphnum_word.isnumeric()) and alph_word:\n",
    "            #word_no == 0 => the word is a Family, Genus, Species\n",
    "            new_group = True\n",
    "            for g in indent_groups:\n",
    "                g_arr = np.array(g)[:,0]\n",
    "                if (x_0, y_0, x_1, y_1)[0] <= np.mean(g_arr) + indent_err and (x_0, y_0, x_1, y_1)[0] >= np.mean(g_arr) - indent_err:\n",
    "                    g.append((x_0, y_0, x_1, y_1))\n",
    "                    new_group = False\n",
    "            if new_group:\n",
    "                indent_groups.append([(x_0, y_0, x_1, y_1)])\n",
    "\n",
    "    def get_indent_group(row):\n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        word_no = row['word_no']\n",
    "        word = row['word']\n",
    "        alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "        \n",
    "        if (len(word) > 1) and ((not alphnum_word.isnumeric()) and (word_no == 0)): \n",
    "            for g_i, g in enumerate(indent_groups):\n",
    "                g_arr = np.array(g)[:,0]\n",
    "                if (x_0, y_0, x_1, y_1)[0] <= np.mean(g_arr) + indent_err and (x_0, y_0, x_1, y_1)[0] >= np.mean(g_arr) - indent_err:\n",
    "                    return g_i\n",
    "\n",
    "    def get_col(row): \n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        return int(x_0 > ((x_min + x_max) / 2))\n",
    "\n",
    "    def n_leftmost_indent(indent_groups, n):\n",
    "        indent_means = []\n",
    "        for g_i, g in enumerate(indent_groups):\n",
    "            g_arr = np.array(g)[:,0]\n",
    "            indent_means.append([g_i, np.mean(g_arr)])\n",
    "\n",
    "        n_smallest = indent_means.sort(key = lambda x : x[1])[:n] #n smallest\n",
    "        return [el[0] for el in n_smallest]\n",
    "\n",
    "    def process_col(row):\n",
    "        nonlocal genus\n",
    "        nonlocal x_0, y_0, x_1, y_1 \n",
    "        nonlocal epitet\n",
    "        nonlocal genus_block_no\n",
    "        word_no = row['word_no']\n",
    "        block_no = row['block_no']\n",
    "        line_no = row['line_no']\n",
    "        word = row['word']\n",
    "\n",
    "        row['epitet'] = np.NaN\n",
    "        row['genus'] = np.NaN\n",
    "        \n",
    "        alph_word = ''.join(e for e in word if e.isalpha())\n",
    "\n",
    "        if line_no == 0 and (word.lower() == 'nouvelle' or word.lower() == 'flore'):\n",
    "            return row\n",
    "\n",
    "        if (not (word.isupper() and word_no == 0)) and len(word) > 1  and alph_word:\n",
    "            if word_no == 0: #epitet, or genus\n",
    "                x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "\n",
    "            alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "            if (not alphnum_word.isnumeric()): \n",
    "                if  x_0 <= g_x0 + indent_err and x_0 >= g_x0 - indent_err:\n",
    "                    if word_no == 0:\n",
    "                        genus = word\n",
    "                        row['genus'] = genus\n",
    "                        genus_block_no = row['block_no']\n",
    "                    elif word_no != 0 and line_no == 0 and block_no == genus_block_no: #info on same line as genus\n",
    "                        #epitet = word\n",
    "                        #print(genus, alphnum_word)\n",
    "                        row['epitet'] = np.NaN\n",
    "                        row['genus'] = genus\n",
    "                        #row['author']\"\"\"\n",
    "                    else:\n",
    "                        row['epitet'] = epitet\n",
    "                        row['genus'] = genus\n",
    "                elif x_0 <= s_x0 + indent_err and x_0 >= s_x0 - indent_err:\n",
    "                    if word_no == 0:\n",
    "                        epitet = word\n",
    "                    row['epitet'] = epitet\n",
    "                    row['genus'] = genus\n",
    "        return row\n",
    "\n",
    "    #page_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    #page_df['page_num'] = np.array([page_num]*page_df.shape[0])\n",
    "    #page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    page_df, pruned_words_df, indent_groups  = preprocessing(pages, page_num)\n",
    "    #indent_groups = []\n",
    "    indent_err = 15\n",
    "\n",
    "    x_min = page_df['x0'].min()\n",
    "    y_min = page_df['y0'].min()\n",
    "    x_max = page_df['x1'].max()\n",
    "    y_max = page_df['y1'].max()\n",
    "    \n",
    "    #page_df.apply(initiate_groups, axis = 1)\n",
    "    #page_df['indent_group'] = page_df.apply(get_indent_group, axis = 1)\n",
    "\n",
    "    page_df['col'] = page_df.apply(get_col, axis = 1)\n",
    "    \n",
    "    x_0, y_0, x_1, y_1, epitet = np.NaN, np.NaN, np.NaN, np.NaN, np.NaN\n",
    "    for c in page_df['col'].unique():\n",
    "        \n",
    "        # what if just one largest? what would that even mean? Hm ... (like what if it's all)\n",
    "        col_df = page_df[(page_df['col'] == c)]\n",
    "        col_indent_groups =  list(col_df[~col_df['indent_group'].isnull()]['indent_group'].unique())\n",
    "        #n_leftmost = n_leftmost_indent(col_indent_groups, 2)\n",
    "        #col_df[col_df['indent_group'] == s_indent]\n",
    "        #if len(n_leftmost) == 2:\n",
    "\n",
    "        s_x0, g_x0 = float('inf'), float('inf')\n",
    "        s_indent, g_indent = -1, -1\n",
    "\n",
    "        for g in col_indent_groups:\n",
    "            mean_x0 = col_df[col_df['indent_group'] == g]['x0'].mean()\n",
    "            if g_x0 > mean_x0:\n",
    "                s_indent, g_indent = g_indent, g\n",
    "                s_x0, g_x0 = g_x0, mean_x0 \n",
    "            elif s_x0 > mean_x0: #and g_x0 <= mean_x0\n",
    "                s_indent = g\n",
    "                s_x0 = mean_x0\n",
    "\n",
    "        #if col_df[col_df['indent_group'] == s_indent]['word'].str.contains('var.|subsp.').any():\n",
    "        \n",
    "        #print(genus, s_x0, g_x0)\n",
    "\n",
    "\n",
    "        species_indent_df = col_df[col_df['indent_group'] == s_indent]\n",
    "        if (species_indent_df['word'] == 'var.').any() or (species_indent_df['word'] == 'subsp.').any():\n",
    "            s_x0, g_x0 = g_x0, float('inf')\n",
    "            s_indent, g_indent = g_indent, -1\n",
    "            #print(\"no genus in a column of page\", page_num)\n",
    "        if (s_x0  < g_x0):\n",
    "            s_x0, g_x0 = g_x0, s_x0\n",
    "            s_indent, g_indent = g_indent, s_indent\n",
    "\n",
    "        if s_indent == -1:\n",
    "            s_x0, g_x0 = g_x0, float('inf')\n",
    "            s_indent, g_indent = g_indent, -1\n",
    "\n",
    "        col_df = col_df.apply(process_col, axis = 1)\n",
    "        page_df.loc[col_df.index, ['genus', 'epitet']] = col_df.loc[col_df.index, ['genus', 'epitet']]\n",
    "        #print(\"g_x0, s_x0, g_indent, s_indent:\", g_x0, s_x0, g_indent, s_indent)\n",
    "    #print(\"genus\", genus)\n",
    "\n",
    "    return page_df, genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author(page_df):\n",
    "    #pruned_df = page_df[(~page_df['genus'].isnull())].reset_index()\n",
    "    epitet_names = page_df[~page_df['epitet'].isnull()]['epitet'].unique()\n",
    "    for i in range(len(page_df['x0'])):\n",
    "        word = page_df.loc[i, 'word']\n",
    "        if word in epitet_names:\n",
    "            #print(word, i)\n",
    "            s = page_df.loc[i, 'word']\n",
    "            g = page_df.loc[i, 'genus']\n",
    "            sub_df = page_df[(page_df['genus'] == g) & (page_df['epitet'] == s) & (page_df['word'] != s)]\n",
    "            \n",
    "            merged = sub_df.groupby('epitet')['word'].agg(' '.join).reset_index()\n",
    "            \n",
    "            concat_str = np.NaN\n",
    "            if len(merged.index):\n",
    "                concat_str = merged['word'].item()\n",
    "            \n",
    "            page_df.loc[i, 'author'] = concat_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23/23 [00:24<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "genus = np.NaN\n",
    "result_ims = []\n",
    "df_list = []\n",
    "\n",
    "for page_num in tqdm(index):\n",
    "    page_df, genus = process_df(page_num, genus)\n",
    "\n",
    "    pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "    image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    plot_genus_blocks(page_df, draw)\n",
    "    plot_epitet_blocks(page_df, draw)\n",
    "    \n",
    "    df_list.append(page_df)\n",
    "    result_ims.append(image)\n",
    "\n",
    "#TIME_STR = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%p\")\n",
    "#result_ims[0].save('../output/index/PDF/vol1_ROI_'+TIME_STR+'.pdf' ,save_all=True, append_images=result_ims[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2/23 [00:02<00:25,  1.23s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 13%|█▎        | 3/23 [00:03<00:23,  1.16s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 17%|█▋        | 4/23 [00:04<00:21,  1.12s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 22%|██▏       | 5/23 [00:05<00:19,  1.07s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 26%|██▌       | 6/23 [00:06<00:17,  1.03s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 35%|███▍      | 8/23 [00:09<00:18,  1.21s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 39%|███▉      | 9/23 [00:10<00:16,  1.17s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 43%|████▎     | 10/23 [00:11<00:14,  1.12s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 48%|████▊     | 11/23 [00:12<00:13,  1.13s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 52%|█████▏    | 12/23 [00:13<00:11,  1.09s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 57%|█████▋    | 13/23 [00:14<00:10,  1.05s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 61%|██████    | 14/23 [00:15<00:10,  1.11s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 70%|██████▉   | 16/23 [00:17<00:07,  1.08s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 83%|████████▎ | 19/23 [00:21<00:04,  1.13s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      " 96%|█████████▌| 22/23 [00:24<00:01,  1.12s/it]/var/folders/fn/y98vt_mj7gl5c447m5vtrn0c0000gn/T/ipykernel_31062/3420006643.py:6: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if word in epitet_names:\n",
      "\n",
      "100%|██████████| 23/23 [00:24<00:00,  1.08s/it]\n"
     ]
    }
   ],
   "source": [
    "genus = np.NaN\n",
    "result_ims = []\n",
    "df_list = []\n",
    "\n",
    "for page_num in tqdm(index):\n",
    "    page_df, genus = process_df(page_num, genus)\n",
    "    get_author(page_df)\n",
    "    \n",
    "    pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "    image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    plot_genus_blocks(page_df, draw, w = 4)\n",
    "    plot_epitet_blocks(page_df, draw, w = 3)\n",
    "    plot_author_blocks(page_df, draw, w = 2)\n",
    "\n",
    "    df_list.append(page_df)\n",
    "    result_ims.append(image)\n",
    "\n",
    "TIME_STR = datetime.now().strftime(\"%Y_%m_%d-%I_%M_%p\")\n",
    "result_ims[0].save('../output/index/PDF/[preprocessed]vol1_ROI_'+TIME_STR+'.pdf' ,save_all=True, append_images=result_ims[1:])\n",
    "\n",
    "df = pd.concat(df_list, axis = 0)\n",
    "df.to_csv('../output/index/CSV/[preprocessed]vol1'+TIME_STR+'.csv')\n",
    "\n",
    "author_pruned_df = df[(~df['author'].isnull()) | (df['word'] == df['genus'])]\n",
    "simple_genus_species_author = author_pruned_df[[\"genus\", \"epitet\", \"author\"]]\n",
    "simple_genus_species_author.to_csv('../output/index/CSV/[preprocessed]vol1_simplified'+TIME_STR+'.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}