{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import fitz\n",
    "import re\n",
    "from PIL import Image, ImageDraw, ImageFont, ImageColor\n",
    "import operator\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_genus_blocks(page_df, draw, color = '#6c899e', w = 3):\n",
    "    genus_list = page_df['genus'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for g in genus_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['genus'] == g)]\n",
    "            g_x0 = temp_df['x0'].min()\n",
    "            g_y0 = temp_df['y0'].min()\n",
    "            g_x1 = temp_df['x1'].max()\n",
    "            g_y1 = temp_df['y1'].max()\n",
    "\n",
    "            draw.rectangle((g_x0, g_y0, g_x1, g_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "        \n",
    "def plot_epitet_blocks(page_df, draw, color = '#54081f', w = 2):\n",
    "    epitet_list = page_df['epitet'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for s in epitet_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['epitet'] == s)]\n",
    "            for g in temp_df['genus'].unique():\n",
    "                    \n",
    "                temp_g_df = temp_df[(temp_df['genus']) == g]\n",
    "                s_x0 = temp_g_df['x0'].min()\n",
    "                s_y0 = temp_g_df['y0'].min()\n",
    "                s_x1 = temp_g_df['x1'].max()\n",
    "                s_y1 = temp_g_df['y1'].max()\n",
    "\n",
    "                draw.rectangle((s_x0, s_y0, s_x1, s_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_blocks(page_df, draw, color = '#4a3757', w = 2):\n",
    "    block_list = page_df['block_no'].unique()\n",
    "    for i in block_list:\n",
    "        df_groupped = page_df[page_df['block_no'] == i]\n",
    "        x0_arr = df_groupped['x0'].min()\n",
    "        y0_arr = df_groupped['y0'].min()\n",
    "        x1_arr = df_groupped['x1'].max()\n",
    "        y1_arr = df_groupped['y1'].max()\n",
    "\n",
    "        draw.rectangle((x0_arr, y0_arr, x1_arr, y1_arr), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_author_blocks(page_df, draw, color = '#a3a3a3', w = 1):\n",
    "    epitet_list = page_df['epitet'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for s in epitet_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['epitet'] == s)]\n",
    "            for g in temp_df['genus'].unique():\n",
    "                temp_g_df = temp_df[(temp_df['genus'] == g) & (temp_df['word'] != s)]\n",
    "                a_x0 = temp_g_df['x0'].min()\n",
    "                a_y0 = temp_g_df['y0'].min()\n",
    "                a_x1 = temp_g_df['x1'].max()\n",
    "                a_y1 = temp_g_df['y1'].max()\n",
    "                \n",
    "                draw.rectangle((a_x0, a_y0, a_x1, a_y1), fill=None, outline=ImageColor.getrgb(color), width = w)\n",
    "\n",
    "def plot_sub_blocks(page_df, draw, color = '#ff6289', w = 1):\n",
    "    sub_list = page_df[(~page_df['sub'].isnull())]['sub'].unique()\n",
    "    for c in page_df['col'].unique():\n",
    "        for s in sub_list:\n",
    "            temp_df = page_df[(page_df['col'] == c) & (page_df['sub'] == s)]\n",
    "            for b in temp_df['block_no'].unique():\n",
    "                temp_b_df = temp_df[(temp_df['block_no'] == b)]\n",
    "                for l in temp_b_df['line_no'].unique():\n",
    "                    temp_l_df = temp_b_df[temp_b_df['line_no'] == l]\n",
    "                    a_x0 = temp_l_df['x0'].min()\n",
    "                    a_y0 = temp_l_df['y0'].min()\n",
    "                    a_x1 = temp_l_df['x1'].max()\n",
    "                    a_y1 = temp_l_df['y1'].max()\n",
    "                \n",
    "                    draw.rectangle((a_x0, a_y0, a_x1, a_y1), fill=None, outline=ImageColor.getrgb(color), width = w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Vol3 Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = \"../input/NOUVELLE FLORE DU LIBAN ET DE LA SYRIE 3.pdf\"\n",
    "doc = fitz.open(pdf_dir)\n",
    "pages = [doc[i] for i in range(doc.pageCount)]\n",
    "index = list(range(555, 583))\n",
    "\n",
    "TARGET_DPI = 300\n",
    "mat = fitz.Matrix(TARGET_DPI/ 72, TARGET_DPI/ 72)\n",
    "\n",
    "indent_groups = []\n",
    "indent_err = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regex based boolean functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(word):\n",
    "    \"\"\"\n",
    "    valid words are words that are:\n",
    "    - at least 2 characters\n",
    "        - unless it's x (symbol for hybrid)\n",
    "    \"\"\"\n",
    "    return (not bool(re.search(r\"[0-9]+[,.]?\", word))) and (len(word) > 1 or word == 'x' or word == 'X' or word == '×' or word == r'\\u00D7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_genus(word):\n",
    "    \"\"\"\n",
    "    A word in the index might be a genus if it satisfies the following properties:\n",
    "    - letters: french alphabet + at most one hyphen (which is not first or last letter)\n",
    "        - first letter upper case\n",
    "        - all but first lowecase \n",
    "    in regex: ^[A-ZÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ]{1}[a-zàâäèéêëîïôœùûüÿç]*[-]?[a-zàâäèéêëîïôœùûüÿç]+$ #ignoring strict beggining and end cause of noise\n",
    "        * based on the current expression it'd also be at least 2 letters long\n",
    "    \"\"\"\n",
    "    regex = r\"[A-ZÀÂÄÈÉÊËÎÏÔŒÙÛÜŸÇ\\u00D7]{1}[a-zàâäèéêëîïôœùûüÿç]*[-]?[a-zàâäèéêëîïôœùûüÿç]+\"\n",
    "    return re.search(regex, word)\n",
    "    \n",
    "\n",
    "def is_epithet(word):\n",
    "    \"\"\"\n",
    "    A word in the index might be an epithet if it satisfies the following properties:\n",
    "    - letters: french alphabet + at most one hyphen (which is not first or last letter)\n",
    "        - all letters lowecase \n",
    "    in regex: ^[a-zàâäèéêëîïôœùûüÿç]+[-]?[a-zàâäèéêëîïôœùûüÿç]+$ #ignoring strict beggining and end cause of noise \n",
    "        * based on the current expression it'd also be at least 2 letters long\n",
    "    \"\"\"\n",
    "    regex = r\"[a-zàâäèéêëîïôœùûüÿç\\u00D7]+[-]?[a-zàâäèéêëîïôœùûüÿç]+\"\n",
    "    return re.search(regex, word)\n",
    "    \n",
    "def is_hybrid(word):\n",
    "    regex = r\"^([Xx\\u00D7])|([Xx\\u00D7]\\.)$\"\n",
    "    return re.search(regex, word)\n",
    "\n",
    "def is_infra(word):\n",
    "    regex = r\"^(var\\.)|(subsp\\.)\"\n",
    "    return re.search(regex, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(page_num, indent_err = 15):\n",
    "    \n",
    "    #initiate dataframe\n",
    "    page_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    \n",
    "    #add page number to dataframe\n",
    "    page_df['page_num'] = np.array([page_num]*page_df.shape[0])\n",
    "    #updating coordinates to represent target DPI\n",
    "    page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    #get x corner coordinates \n",
    "    x_min = page_df['x0'].min()\n",
    "    x_max = page_df['x1'].max()\n",
    "\n",
    "    #invalid words dataframe -- for error checking\n",
    "    pruned_words_df = page_df[~page_df[\"word\"].apply(valid)].reset_index()\n",
    "    #prune out invalid words (based on function valid)\n",
    "    page_df = page_df[page_df[\"word\"].apply(valid)].reset_index()\n",
    "    \n",
    "    indent_groups = []\n",
    "    blocks = page_df['block_no'].unique()\n",
    "    for b in blocks:\n",
    "        lines = page_df[page_df['block_no'] == b]['line_no'].unique()\n",
    "        for l in lines:\n",
    "            #reset word_no values (useful for cases where word that was originally at 0th index was pruned out)\n",
    "            cond = (page_df['line_no'] == l) & (page_df['block_no'] == b)\n",
    "            num_words = len(page_df[cond]['word_no'])\n",
    "            page_df.loc[cond, 'word_no'] = np.arange(num_words).astype(int) #this is slowww\n",
    "            #set column number (0 or 1)\n",
    "            x_0 = page_df[cond]['x0'].min()\n",
    "            #THIS DOESN'T WORK AAAA -- issue was with line no thing\n",
    "            if not np.isnan(x_0):\n",
    "                page_df.loc[cond, 'col_no'] = np.array([int(x_0 > ((x_min + x_max) / 2))]*num_words).astype(int)\n",
    "\n",
    "                #initiate indent groups -- only first word should get an indent_group value \n",
    "                new_group = True\n",
    "                for g_i in range(len(indent_groups)):\n",
    "                    g = indent_groups[g_i]\n",
    "                    g_arr = np.array(g)\n",
    "                    if x_0 <= np.mean(g_arr) + indent_err and x_0 >= np.mean(g_arr) - indent_err:\n",
    "                        g.append(x_0)\n",
    "                        new_group = False\n",
    "                        page_df.loc[cond, 'indent_group'] = np.array([g_i]*num_words).astype(int)\n",
    "                if new_group:\n",
    "                    indent_groups.append([x_0])\n",
    "                    g_i = len(indent_groups) - 1\n",
    "                    page_df.loc[cond, 'indent_group'] = np.array([g_i]*num_words).astype(int)\n",
    "\n",
    "\n",
    "    #return updated page_df, pruned_words_df, indent groups\n",
    "    return page_df.reset_index(), pruned_words_df, indent_groups\n",
    "\n",
    "#https://stackoverflow.com/questions/53468558/adding-image-to-pandas-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding indentations associated with genus, epithet, infra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = ['genus', 'epithet', 'infra', 'author', 'misc.']\n",
    "def n_leftmost_indent(df, n):\n",
    "    \"\"\"return a tuple with at most 3 elements each element itself is a tuple containing indent group, mean, group len\"\"\"\n",
    "    indent_groups = [(g, df[(df['indent_group'] == g) & (df['word_no'] == 0)]['x0'].mean(), len(df[(df['indent_group'] == g) & (df['word_no'] == 0)]['x0'])) for g in df['indent_group'].unique()]\n",
    "    indent_groups.sort(key = lambda x : x[1])\n",
    "    return indent_groups[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_genusEpithetInfra_indent(col_df):\n",
    "    leftmost_3_indents = n_leftmost_indent(col_df, 3) \n",
    "    min_gap = 25\n",
    "    max_gap = 50\n",
    "\n",
    "    # possibly not specific enough\n",
    "    # first identifying indent based don distance from one another only\n",
    "    if len(leftmost_3_indents) == 3:\n",
    "        if leftmost_3_indents[0][1] < max_gap:\n",
    "            leftmost_3_indents = leftmost_3_indents[1:]\n",
    "        elif ((leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) > max_gap or \\\n",
    "            (leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) < min_gap): #comparing first two (if satisfied last two will be checked in next if block)\n",
    "            leftmost_3_indents = [max(leftmost_3_indents[1:], key = lambda x : x[2])] + [leftmost_3_indents[2]]\n",
    "        elif (leftmost_3_indents[2][1] - leftmost_3_indents[1][1]) > max_gap or \\\n",
    "            (leftmost_3_indents[2][1] - leftmost_3_indents[1][1]) < min_gap: #comparing last two\n",
    "            leftmost_3_indents = [leftmost_3_indents[0]] + [max(leftmost_3_indents[1:], key = lambda x : x[2])]\n",
    "\n",
    "    if len(leftmost_3_indents) == 2:\n",
    "        if leftmost_3_indents[0][1] < max_gap:\n",
    "            leftmost_3_indents = leftmost_3_indents[1]\n",
    "        elif (leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) > max_gap or (leftmost_3_indents[1][1] - leftmost_3_indents[0][1]) < min_gap:\n",
    "            leftmost_3_indents = [max(leftmost_3_indents, key = lambda x : x[2])]\n",
    "\n",
    "    has_genus, has_epithet, has_infra = False, False, False\n",
    "    genus_indent, epithet_indent, infra_indent = -1, -1, -1\n",
    "    if len(leftmost_3_indents) == 3:\n",
    "        has_genus, has_epithet, has_infra = True, True, True\n",
    "        genus_indent, epithet_indent, infra_indent = [el[0] for el in leftmost_3_indents]\n",
    "    elif len(leftmost_3_indents) == 2:\n",
    "        if col_df[col_df['indent_group'] == leftmost_3_indents[1][0]]['word'].apply(is_infra).any():\n",
    "            has_genus, has_epithet, has_infra = False, True, True\n",
    "            epithet_indent, infra_indent = [el[0] for el in leftmost_3_indents]\n",
    "        else:\n",
    "            has_genus, has_epithet, has_infra = True, True, False\n",
    "            genus_indent, epithet_indent = [el[0] for el in leftmost_3_indents]\n",
    "    elif len(leftmost_3_indents) == 2: \n",
    "        has_genus, has_epithet, has_infra = False, True, False\n",
    "        epithet_indent = leftmost_3_indents[0][0]\n",
    "\n",
    "    return genus_indent, epithet_indent, infra_indent, leftmost_3_indents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yeet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[(df['page_num'] == 555) & (df['col_no'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_indentations(page_df, indent_groups): #column level\n",
    "    process_genus, process_epithet, process_infra = False, False, False\n",
    "    n_smallest = n_leftmost_indent(___)\n",
    "    means = [el[1] for el in n_smallest]\n",
    "    num_indents = len(n_smallest)\n",
    "    if num_indents == 1: #all must be epithet names\n",
    "        process_genus, process_epithet, process_infra = False, True, False\n",
    "    elif num_indents == 2:\n",
    "        if means[0] + 40 < means[1]: #second indentation is too far away-- treat it as 1 indentation\n",
    "            process_genus, process_epithet, process_infra = False, True, False\n",
    "        else: #Assume genus is different \n",
    "\n",
    "    elif num_indents == 3: #genus, epithet, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_indent_groups(col_df):\n",
    "    #get indent groups etc etc ... sort them and pick 3 left most ones. Only keep them if they are within 100s of each other (if 3 returned)\n",
    "    for g in indent_group: \n",
    "        #if any of the words satisfy is_hybrid or is_infra that indentation is infra \n",
    "        #not checking hybrid because hybrid can happen at genus, epithet levels too \n",
    "        # so in indent_type we set that to infra\n",
    "            #though if we know we are in the third indentation checking for infra then is reasonable? (can do this in process cols perhaps?)\n",
    "        # another criterion can be if it's within 50 if the x_0 of the epithet and word_no == 0(so this will kinda be like a second pass thing if no infra species levels were detected)\n",
    "        # maybe this max min situation can be ignored at the beggining since pruned dataframe though? -- lets not \n",
    "    # if 1 group -- all epithet\n",
    "    # if 2 groups -- & #max - min < 50 \n",
    "    #   check if any can be infra level \n",
    "    #   if so epithet and infra\n",
    "    #   else genus epithet\n",
    "    # else #max - min > 50 \n",
    "    #   ignore second, first is epithet\n",
    "    #if 3 groups #\n",
    "    #    genus, epithet, infra \n",
    "    # all the max - min conds \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_col(col_df, genus, epithet, entry_no, g_indent, e_indent):\n",
    "    blocks = col_df['block_no'].unique()\n",
    "    for b in blocks:\n",
    "        lines = col_df[col_df['block_no'] == b]['line_no'].unique()\n",
    "        for l in lines:\n",
    "            cond = (col_df['line_no'] == l) & (col_df['block_no'] == b)\n",
    "            words = col_df[cond]['word_no'].unique()\n",
    "            for w in words:\n",
    "                word_level_con = (col_df['line_no'] == l) & (col_df['block_no'] == b) & (col_df['word_no'] == w)\n",
    "                word = col_df[word_level_con]['word']\n",
    "                col_df.loc[col_df.index, ['genus', 'epitet', 'sub']]\n",
    "                # if len of word is 1 add to error checking list thing? \n",
    "                if w == 0 or process_hybrid:\n",
    "                    process_hybrid = False\n",
    "                    if len(words) > 1 and is_hybrid(word):\n",
    "                        process_hybrid = True\n",
    "                    #now only gotta say INDENT AND satisfies these paterns\n",
    "                    if is_genus(word):\n",
    "                        genus = word\n",
    "                        #put genus words here\n",
    "                    elif is_epithet(word):\n",
    "                        epithet = word\n",
    "                        #put genus word here\n",
    "                        #pit epithet word  here\n",
    "                    elif is_infra(word):\n",
    "                        process_infra = True\n",
    "                        #set word as infra type\n",
    "                    else:\n",
    "                        #label it uncatagorizable?\n",
    "                        process_infra = False\n",
    "                elif process_infra == True:\n",
    "                    # assign first word to infra column and rest to author\n",
    "                    #set infra to false\n",
    "                    process_infra = False\n",
    "                    #if it's not an epithet satisfying word ... redflag! \n",
    "                else:\n",
    "                    #what ever is left has to be author.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:08<00:00,  3.47it/s]\n"
     ]
    }
   ],
   "source": [
    "genus = np.NaN\n",
    "result_ims = []\n",
    "df_list = []\n",
    "pruned_list = []\n",
    "\n",
    "for page_num in tqdm(index):\n",
    "    page_df, pruned_df, indent_group = preprocessing(page_num)\n",
    "    df_list.append(page_df)\n",
    "    pruned_list.append(pruned_df)\n",
    "    \n",
    "#result_ims[0].save('../output/index/PDF/vol3_withSub_ROIV2.pdf',save_all=True, append_images=result_ims[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, axis = 0)\n",
    "pruned_df = pd.concat(pruned_list, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_html('../output/index/vol3.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:08<00:00,  3.20it/s]\n"
     ]
    }
   ],
   "source": [
    "genus = np.NaN\n",
    "result_ims = []\n",
    "\n",
    "i=0\n",
    "for page_num in tqdm(index):\n",
    "    page_df = df_list[i]\n",
    "    i+=1\n",
    "    #get_author(page_df)\n",
    "    \n",
    "    pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "    image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    plot_blocks(page_df, draw, w = 4)\n",
    "    #plot_epitet_blocks(page_df, draw, w = 3)\n",
    "    #plot_author_blocks(page_df, draw, w = 2)\n",
    "    #plot_sub_blocks(page_df, draw, w = 1)\n",
    "\n",
    "    #df_list.append(page_df)\n",
    "    result_ims.append(image)\n",
    "    \n",
    "result_ims[0].save('../output/index/PDF/vol3_withSub_ROIV2.pdf',save_all=True, append_images=result_ims[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(page_num, genus = np.NaN, genus_block_no = np.NaN):\n",
    "    def initiate_groups(row):\n",
    "        #return row\n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        word_no = row['word_no']\n",
    "        word = row['word']\n",
    "        alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "        alph_word = ''.join(e for e in word if e.isalpha())\n",
    "        \n",
    "        if row['line_no'] == 0 and (word.lower() == 'nouvelle' or word.lower() == 'flore'):\n",
    "            return \n",
    "        if (word_no == 0) and (not alphnum_word.isnumeric()) and alph_word:\n",
    "            #word_no == 0 => the word is a Family, Genus, Species\n",
    "            new_group = True\n",
    "            for g in indent_groups:\n",
    "                g_arr = np.array(g)[:,0]\n",
    "                if (x_0, y_0, x_1, y_1)[0] <= np.mean(g_arr) + indent_err and (x_0, y_0, x_1, y_1)[0] >= np.mean(g_arr) - indent_err:\n",
    "                    g.append((x_0, y_0, x_1, y_1))\n",
    "                    new_group = False\n",
    "            if new_group:\n",
    "                indent_groups.append([(x_0, y_0, x_1, y_1)])\n",
    "\n",
    "    def get_indent_group(row):\n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        word_no = row['word_no']\n",
    "        word = row['word']\n",
    "        alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "        \n",
    "        if (len(word) > 1) and ((not alphnum_word.isnumeric()) and (word_no == 0)): \n",
    "            for g_i, g in enumerate(indent_groups):\n",
    "                g_arr = np.array(g)[:,0]\n",
    "                if (x_0, y_0, x_1, y_1)[0] <= np.mean(g_arr) + indent_err and (x_0, y_0, x_1, y_1)[0] >= np.mean(g_arr) - indent_err:\n",
    "                    return g_i\n",
    "\n",
    "    def get_col(row): \n",
    "        x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "        return int(x_0 > ((x_min + x_max) / 2))\n",
    "\n",
    "    def n_leftmost_indent(indent_groups, n):\n",
    "        indent_means = []\n",
    "        for g_i, g in enumerate(indent_groups):\n",
    "            g_arr = np.array(g)[:,0]\n",
    "            indent_means.append([g_i, np.mean(g_arr)])\n",
    "\n",
    "        n_smallest = indent_means.sort(key = lambda x : x[1])[:n] #n smallest\n",
    "        return [el[0] for el in n_smallest]\n",
    "\n",
    "    def process_col(row):\n",
    "        nonlocal genus\n",
    "        nonlocal x_0, y_0, x_1, y_1 \n",
    "        nonlocal epitet\n",
    "        nonlocal sub\n",
    "        nonlocal genus_block_no\n",
    "        word_no = row['word_no']\n",
    "        block_no = row['block_no']\n",
    "        line_no = row['line_no']\n",
    "        word = row['word']\n",
    "        row['epitet'] = np.NaN\n",
    "        row['genus'] = np.NaN\n",
    "        row['sub'] = np.NaN\n",
    "        \n",
    "        alph_word = ''.join(e for e in word if e.isalpha())\n",
    "\n",
    "        if line_no == 0 and (word.lower() == 'nouvelle' or word.lower() == 'flore'):\n",
    "            return row\n",
    "\n",
    "        if (not (word.isupper() and word_no == 0)) and len(word) > 1  and alph_word:\n",
    "            if word_no == 0: #epitet, or genus\n",
    "                x_0, y_0, x_1, y_1 = row['x0'], row['y0'], row['x1'], row['y1']\n",
    "\n",
    "            alphnum_word = ''.join(e for e in word if e.isalnum())\n",
    "            if (not alphnum_word.isnumeric()): \n",
    "                if  x_0 <= g_x0 + indent_err and x_0 >= g_x0 - indent_err:\n",
    "                    if word_no == 0:\n",
    "                        genus = word\n",
    "                        row['genus'] = genus\n",
    "                        genus_block_no = row['block_no']\n",
    "                    elif word_no != 0 and line_no == 0 and block_no == genus_block_no: #info on same line as genus\n",
    "                        #epitet = word\n",
    "                        #print(genus, alphnum_word)\n",
    "                        row['epitet'] = np.NaN\n",
    "                        row['genus'] = genus\n",
    "                        #row['author']\"\"\"\n",
    "                        row['sub'] = np.NaN\n",
    "                    else:\n",
    "                        row['epitet'] = epitet\n",
    "                        row['genus'] = genus\n",
    "                        row['sub'] = np.NaN\n",
    "                elif x_0 <= s_x0 + indent_err and x_0 >= s_x0 - indent_err:\n",
    "                    if word_no == 0:\n",
    "                        epitet = word\n",
    "                        sub = ''\n",
    "                    row['epitet'] = epitet\n",
    "                    row['genus'] = genus\n",
    "                    row['sub'] = np.NaN\n",
    "                elif x_0 <= sub_x0 + indent_err and x_0 >= sub_x0 - indent_err:\n",
    "                    #word_no == 0 and (word == 'var.' or word == 'subsp.' or word == 'x' or word == 'X'): #assuming at least genus line exists\n",
    "                    if word_no == 0:\n",
    "                        sub = word\n",
    "                    row['epitet'] = epitet\n",
    "                    row['genus'] = genus\n",
    "                    #print(word_no)\n",
    "                    row['sub'] = sub + \" \" + genus + \" \" + epitet\n",
    "\n",
    "        return row\n",
    "\n",
    "    #page_df = pd.DataFrame(pages[page_num].get_text_words(), columns =['in_x0', 'in_y0', 'in_x1', 'in_y1', 'word', 'block_no', 'line_no', 'word_no'])\n",
    "    #page_df['page_num'] = np.array([page_num]*page_df.shape[0])\n",
    "    #page_df['x0'], page_df['y0'], page_df['x1'], page_df['y1'] = page_df['in_x0']*TARGET_DPI/ 72, page_df['in_y0']*TARGET_DPI/ 72, page_df['in_x1']*TARGET_DPI/ 72, page_df['in_y1']*TARGET_DPI/ 72\n",
    "    page_df = preprocessing(page_num)\n",
    "    indent_groups = []\n",
    "    indent_err = 15\n",
    "    sub = ''\n",
    "    x_min = page_df['x0'].min()\n",
    "    y_min = page_df['y0'].min()\n",
    "    x_max = page_df['x1'].max()\n",
    "    y_max = page_df['y1'].max()\n",
    "    \n",
    "    page_df.apply(initiate_groups, axis = 1)\n",
    "    page_df['indent_group'] = page_df.apply(get_indent_group, axis = 1)\n",
    "\n",
    "    page_df['col'] = page_df.apply(get_col, axis = 1)\n",
    "    \n",
    "    x_0, y_0, x_1, y_1, epitet = np.NaN, np.NaN, np.NaN, np.NaN, np.NaN\n",
    "    for c in page_df['col'].unique():\n",
    "        \n",
    "        # what if just one largest? what would that even mean? Hm ... (like what if it's all)\n",
    "        col_df = page_df[(page_df['col'] == c)]\n",
    "        col_indent_groups =  list(col_df[~col_df['indent_group'].isnull()]['indent_group'].unique())\n",
    "        #n_leftmost = n_leftmost_indent(col_indent_groups, 2)\n",
    "        #col_df[col_df['indent_group'] == s_indent]\n",
    "        #if len(n_leftmost) == 2:\n",
    "\n",
    "        s_x0, g_x0, sub_x0 = float('inf'), float('inf'), float('inf')\n",
    "        s_indent, g_indent, sub_indent = -1, -1, -1\n",
    "\n",
    "        for g in col_indent_groups:\n",
    "            mean_x0 = col_df[col_df['indent_group'] == g]['x0'].mean()\n",
    "            sub_list = [\"var.\", \"subsp.\", \"x\", \"X\"]\n",
    "\n",
    "            if (col_df[col_df['indent_group'] == g]['word'].apply(lambda x : x  in sub_list)).any():\n",
    "                sub_indent = g\n",
    "                sub_x0 = mean_x0\n",
    "            if g_x0 > mean_x0:\n",
    "                s_indent, g_indent = g_indent, g\n",
    "                s_x0, g_x0 = g_x0, mean_x0 \n",
    "            elif s_x0 > mean_x0: #and g_x0 <= mean_x0\n",
    "                s_indent = g\n",
    "                s_x0 = mean_x0\n",
    "            \"\"\"elif sub_x0 > mean_x0:#and g_x0 <= mean_x0 and s_x0 <= mean_x0\n",
    "                sub_indent = g\n",
    "                sub_x0 = mean_x0\"\"\"\n",
    "\n",
    "        #if col_df[col_df['indent_group'] == s_indent]['word'].str.contains('var.|subsp.').any():\n",
    "        \n",
    "        #print(genus, s_x0, g_x0)\n",
    "\n",
    "\n",
    "        \"\"\"species_indent_df = col_df[col_df['indent_group'] == s_indent]\n",
    "        if (species_indent_df['word'] == 'var.').any() or (species_indent_df['word'] == 'subsp.').any() or (species_indent_df['word'] == 'x').any() or (species_indent_df['word'] == 'X').any():\n",
    "            s_x0, g_x0, sub_x0 = g_x0, float('inf'), s_x0\n",
    "            s_indent, g_indent, sub_indent = g_indent, -1, s_indent\n",
    "            #print(\"no genus in a column of page\", page_num)\n",
    "\n",
    "        if (s_x0  < g_x0): #the swap thing doesn't account for sub_indent level just yet ... \n",
    "            s_x0, g_x0 = g_x0, s_x0\n",
    "            s_indent, g_indent = g_indent, s_indent\n",
    "\n",
    "        if s_indent == -1: #subspecies must not exist in this case so won't worry about it \n",
    "            s_x0, g_x0 = g_x0, float('inf')\n",
    "            s_indent, g_indent = g_indent, -1\n",
    "\n",
    "        col_df = col_df.apply(process_col, axis = 1)\n",
    "        page_df.loc[col_df.index, ['genus', 'epitet', 'sub']] = col_df.loc[col_df.index, ['genus', 'epitet', 'sub']]\n",
    "        #print(\"g_x0, s_x0, g_indent, s_indent:\", g_x0, s_x0, g_indent, s_indent)\"\"\"\n",
    "        species_indent_df = col_df[col_df['indent_group'] == s_indent]\n",
    "        if (species_indent_df['word'] == 'var.').any() or (species_indent_df['word'] == 'subsp.').any():\n",
    "            s_x0, g_x0 = g_x0, float('inf')\n",
    "            s_indent, g_indent = g_indent, -1\n",
    "            #print(\"no genus in a column of page\", page_num)\n",
    "\n",
    "        if (s_x0  < g_x0):\n",
    "            s_x0, g_x0 = g_x0, s_x0\n",
    "            s_indent, g_indent = g_indent, s_indent\n",
    "\n",
    "        if s_indent == -1:\n",
    "            s_x0, g_x0 = g_x0, float('inf')\n",
    "            s_indent, g_indent = g_indent, -1\n",
    "    #print(\"genus\", genus)\n",
    "        col_df = col_df.apply(process_col, axis = 1)\n",
    "        page_df.loc[col_df.index, ['genus', 'epitet', 'sub']] = col_df.loc[col_df.index, ['genus', 'epitet', 'sub']]\n",
    "    return page_df, genus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author(page_df):\n",
    "    #pruned_df = page_df[(~page_df['genus'].isnull())].reset_index()\n",
    "    epitet_names = page_df[~page_df['epitet'].isnull()]['epitet'].unique()\n",
    "    genus_names = page_df[~page_df['genus'].isnull()]['genus'].unique()\n",
    "    sub_names = page_df[~page_df['sub'].isnull()]['sub'].unique()\n",
    "    for i in range(len(page_df['x0'])):\n",
    "        word = page_df.loc[i, 'word']\n",
    "        sub = page_df.loc[i, 'sub']\n",
    "        line_no = page_df.loc[i, 'line_no']\n",
    "        block_no = page_df.loc[i, 'block_no']\n",
    "        if word in epitet_names:\n",
    "            #print(word, i)\n",
    "            s = page_df.loc[i, 'word']\n",
    "            g = page_df.loc[i, 'genus']\n",
    "            sub_df = page_df[(page_df['genus'] == g) & (page_df['epitet'] == s) & (page_df['word'] != s)]\n",
    "            \n",
    "            merged = sub_df.groupby('epitet')['word'].agg(' '.join).reset_index()\n",
    "            \n",
    "            concat_str = np.NaN\n",
    "            if len(merged.index):\n",
    "                concat_str = merged['word'].item()\n",
    "            \n",
    "            page_df.loc[i, 'author'] = concat_str\n",
    "            page_df.loc[i, 'sub_type'] = np.NaN\n",
    "            page_df.loc[i, 'sub_name'] = np.NaN\n",
    "\n",
    "        if word in genus_names:\n",
    "            g = page_df.loc[i, 'genus']\n",
    "            g_block_no = page_df.loc[i, 'block_no']\n",
    "            sub_df = page_df[(page_df['genus'] == g) & (page_df['block_no'] == g_block_no) & (page_df['word_no'] != 0) & (page_df['line_no'] == 0)]\n",
    "            merged = sub_df.groupby('genus')['word'].agg(' '.join).reset_index()\n",
    "            concat_str = np.NaN\n",
    "            if len(merged.index):\n",
    "                #print(g, word)\n",
    "                concat_str = merged['word'].item()\n",
    "            page_df.loc[i, 'author'] = concat_str\n",
    "            page_df.loc[i, 'sub_type'] = np.NaN\n",
    "            page_df.loc[i, 'sub_name'] = np.NaN\n",
    "        if sub in sub_names:\n",
    "            #print(sub.split(' '))\n",
    "            sub_type, g, s = sub.split(' ')#[0]\n",
    "            #s = page_df.loc[i, 'word']\n",
    "            #g = page_df.loc[i, 'genus']\n",
    "            sub_df = page_df[(page_df['genus'] == g) & (page_df['epitet'] == s) & \\\n",
    "                            (page_df['word'] != sub_type) & (page_df['sub'] == sub) & (page_df['line_no'] == line_no) & (page_df['block_no'] == block_no)]\n",
    "            merged = sub_df.groupby('sub')['word'].agg(' '.join).reset_index()\n",
    "            concat_str = np.NaN\n",
    "            name, aut = np.NaN, np.NaN\n",
    "            if len(merged.index):\n",
    "                #print(g, word)\n",
    "                concat_str = merged['word'].item()\n",
    "                #print(concat_str)\n",
    "                #print(concat_str.split(' ', 1))\n",
    "                if len(concat_str.split(' ', 1)) == 2:\n",
    "                    name, aut = concat_str.split(' ', 1)\n",
    "                elif len(concat_str.split(' ', 1)) == 1:\n",
    "                    name = concat_str\n",
    "            page_df.loc[i, 'sub_type'] = sub_type\n",
    "            page_df.loc[i, 'sub_name'] = name\n",
    "            page_df.loc[i, 'sub_author'] = aut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genus = np.NaN\n",
    "result_ims = []\n",
    "df_list = []\n",
    "\n",
    "for page_num in tqdm(index):\n",
    "    page_df, genus = process_df(page_num, genus)\n",
    "    get_author(page_df)\n",
    "    \n",
    "    pix_map = doc.get_page_pixmap(page_num,matrix=mat)\n",
    "    image = Image.open(io.BytesIO(pix_map.tobytes()))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    plot_genus_blocks(page_df, draw, w = 4)\n",
    "    plot_epitet_blocks(page_df, draw, w = 3)\n",
    "    plot_author_blocks(page_df, draw, w = 2)\n",
    "    plot_sub_blocks(page_df, draw, w = 1)\n",
    "\n",
    "    df_list.append(page_df)\n",
    "    result_ims.append(image)\n",
    "    \n",
    "result_ims[0].save('../output/index/PDF/vol3_withSub_ROIV2.pdf',save_all=True, append_images=result_ims[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(df_list, axis = 0)\n",
    "df.to_csv('../output/index/CSV/vol3_sub.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING + OLDER CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['page_num'] == 555) & ~df['sub'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[~df['sub'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df[(sub_df['word'] != sub_df['sub'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(~df['sub'].isnull()) & (df['page_num'] == 555)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['block_no'] == 7) & (df['page_num'] == 555)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sub_df['page_num']:\n",
    "    for b in sub_df[sub_df['page_num'] == i]['block_no']:\n",
    "        for l in sub_df[(sub_df['page_num'] == i) & (sub_df['block_no'] == b)]['line_no']:\n",
    "            str_sub = ''\n",
    "            for w in sub_df[(sub_df['page_num'] == i) & (sub_df['block_no'] == b) & (sub_df['line_no'] == l)]['word_no']:\n",
    "                word = sub_df[(sub_df['page_num'] == i) & (sub_df['block_no'] == b) & (sub_df['line_no'] == l) & (sub_df['word_no'] == w)]['word']\n",
    "                if w == 0 and (word == 'var.' or word == 'subsp.' or word == 'x' or word == 'X'): #assuming at least genus line exists\n",
    "                    sub = word\n",
    "                else: \n",
    "                    sub = word\n",
    "                    str_sub += word + ' '\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['sub'] == 'x') | (df['sub'] == 'X')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub(page_df):\n",
    "    #pruned_df = page_df[(~page_df['genus'].isnull())].reset_index()\n",
    "    epitet_names = page_df[~page_df['epitet'].isnull()]['epitet'].unique()\n",
    "    genus_names = page_df[~page_df['genus'].isnull()]['genus'].unique()\n",
    "    sub_names = ['var.', 'subsp.', 'x', 'X'] \n",
    "\n",
    "    for i in range(len(page_df['x0'])):\n",
    "        word = page_df.loc[i, 'word']\n",
    "        if word in sub_names:\n",
    "            #print(word, i)\n",
    "            s = page_df.loc[i, 'word']\n",
    "            g = page_df.loc[i, 'genus']\n",
    "            sub_df = page_df[(page_df['genus'] == g) & (page_df['epitet'] == s) & (page_df['word'] != s)]\n",
    "            \n",
    "            merged = sub_df.groupby('epitet')['word'].agg(' '.join).reset_index()\n",
    "            \n",
    "            concat_str = np.NaN\n",
    "            if len(merged.index):\n",
    "                concat_str = merged['word'].item()\n",
    "            \n",
    "            page_df.loc[i, 'author'] = concat_str\n",
    "\n",
    "        if word in genus_names:\n",
    "            g = page_df.loc[i, 'genus']\n",
    "            g_block_no = page_df.loc[i, 'block_no']\n",
    "            sub_df = page_df[(page_df['genus'] == g) & (page_df['block_no'] == g_block_no) & (page_df['word_no'] != 0) & (page_df['line_no'] == 0)]\n",
    "            merged = sub_df.groupby('genus')['word'].agg(' '.join).reset_index()\n",
    "            concat_str = np.NaN\n",
    "            if len(merged.index):\n",
    "                #print(g, word)\n",
    "                concat_str = merged['word'].item()\n",
    "            page_df.loc[i, 'author'] = concat_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_pruned_df = df[(~df['author'].isnull()) | (df['word'] == df['genus'])]\n",
    "simple_genus_species_author = author_pruned_df[[\"genus\", \"epitet\", \"author\"]]\n",
    "simple_genus_species_author.to_csv('../output/index/CSV/vol3_simplified.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}